{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_management\n",
    "from data_management import load_stack\n",
    "from data_management import load_data\n",
    "\n",
    "import interactive_plot\n",
    "\n",
    "import metrics\n",
    "from metrics import statistics\n",
    "from metrics import confusion_matrix\n",
    "from metrics import error_distribution\n",
    "from metrics import error_borders\n",
    "from metrics import PR_curve\n",
    "\n",
    "import generator_extended\n",
    "\n",
    "import unet\n",
    "from unet import load_model_unet\n",
    "from unet import predict_net\n",
    "from unet import get_unet\n",
    "from unet import train\n",
    "from unet import execute_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATAPATH = '/raid/mpsych/CACTAS/DATA/Nathan Arnett Calcification/'\n",
    "images_file = os.path.join(DATAPATH, 'images_cropped.npy')\n",
    "labels_file = os.path.join(DATAPATH, 'labels_cropped.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float)\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    \n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = images[0:450]\n",
    "imgs_mask_train = labels[0:450]\n",
    "imgs_test = images[450:]\n",
    "imgs_mask_test = labels[450:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3b68354760>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_train[30],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f316e937c10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_mask_train[30],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 512, 512, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_filters 16\n",
      "conv1 shape: (None, 32, 32, 16)\n",
      "conv1 shape: (None, 32, 32, 16)\n",
      "pool1 shape: (None, 16, 16, 16)\n",
      "conv2 shape: (None, 16, 16, 32)\n",
      "conv2 shape: (None, 16, 16, 32)\n",
      "pool2 shape: (None, 8, 8, 32)\n",
      "conv3 shape: (None, 8, 8, 64)\n",
      "conv3 shape: (None, 8, 8, 64)\n",
      "pool3 shape: (None, 4, 4, 64)\n",
      "using jaccard loss!\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(0.0001, 32,32, dr_rate=0.2, diceloss=False, jaccardloss=True, \n",
    "                 focalloss=False, customloss=False, start_filters=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 16)   160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 16)   2320        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 16)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 32)     0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 64)     18496       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 64)     0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 128)    73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 4, 4, 128)    147584      conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 4, 128)    0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 128)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 2, 2, 256)    295168      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 2, 2, 256)    590080      conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2, 2, 256)    0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 4, 4, 256)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 128)    131200      up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 4, 4, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 128)    295040      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 4, 4, 128)    147584      conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 8, 8, 128)    0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 64)     32832       up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 128)    0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 64)     73792       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 16, 16, 64)   0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 64)   16448       up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 96)   0           conv2d_51[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 32)   27680       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 32, 32, 32)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 16)   2064        up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 32)   0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 16)   4624        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 16)   2320        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 2)    290         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 1)    3           conv2d_70[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,958,533\n",
      "Trainable params: 1,958,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 512, 512, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "data details:\n",
      "imgs_train.shape (450, 32, 32, 1)\n",
      "imgs_mask_train.shape (450, 32, 32, 1)\n",
      "imgs_test.shape (53, 32, 32, 1)\n",
      "imgs_mask_test.shape (53, 32, 32, 1)\n",
      "imgs_train.dtype float64\n",
      "imgs_mask_train.dtype float64\n",
      "imgs_test.dtype float64\n",
      "imgs_mask_test.dtype float64\n",
      "balance:\n",
      "train_total_px 460800\n",
      "train_labeled_positive 0\n",
      "train_fraction_positive 0.0\n",
      "min, max train 0.04451827242524917 0.6501587301587302\n",
      "train_total_px 460800 number 0/1 in mask 460800\n",
      "test_total_px 54272\n",
      "test_labeled_positive 0\n",
      "test_fraction_positive 0.0\n",
      "min, max test 0.06253229974160207 0.6069946650859513\n",
      "loading data done\n",
      "saving model checkpoints in /tmp/models/A100test/\n",
      "saving logfile in  /tmp/models/A100test/log.txt\n",
      "augmenting on the fly...\n",
      "computing statistics...\n",
      "<generator object train.<locals>.combine_generator at 0x7f315853b3c0>\n",
      "starting...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ConcatOp : Dimensions of inputs should match: shape[0] = [50,128,64,64] vs. shape[1] = [50,128,4,4]\n\t [[node model_2/concatenate_8/concat (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:3063) ]] [Op:__inference_train_function_69831]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_2/concatenate_8/concat:\n model_2/conv2d_58/Relu (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:4700)\t\n model_2/dropout_4/dropout/Mul_1 (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/layers/core.py:208)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2110435/1894089883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(model, imgs_train[:,0:32,0:32,:], imgs_mask_train[:,0:32,0:32,:], imgs_test[:,0:32,0:32,:], imgs_mask_test[:,0:32,0:32,:],\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0;34m'/tmp/models/A100test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       perform_flipping=True, perform_rotation=True, to_dir=False, train_on_borders=False)\n",
      "\u001b[0;32m~/Projects/CACTAS/_EXPERIMENTS/a-fully-supervised-unet/unet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, imgs_train, imgs_mask_train, imgs_test, imgs_mask_test, model_name, bt_size, train_epochs, iter_per_epoch, val_steps, finetune_path, perform_centering, perform_flipping, perform_rotation, perform_standardization, plot_graph, verbosity, to_dir, train_on_borders)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     model.fit_generator(train_generator,\n\u001b[0m\u001b[1;32m    169\u001b[0m                              \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1916\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1918\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  ConcatOp : Dimensions of inputs should match: shape[0] = [50,128,64,64] vs. shape[1] = [50,128,4,4]\n\t [[node model_2/concatenate_8/concat (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:3063) ]] [Op:__inference_train_function_69831]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_2/concatenate_8/concat:\n model_2/conv2d_58/Relu (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:4700)\t\n model_2/dropout_4/dropout/Mul_1 (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/layers/core.py:208)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "train(model, imgs_train[:,0:32,0:32,:], imgs_mask_train[:,0:32,0:32,:], imgs_test[:,0:32,0:32,:], imgs_mask_test[:,0:32,0:32,:],\n",
    "      '/tmp/models/A100test', 50, 1000, verbosity=1, \n",
    "      perform_flipping=True, perform_rotation=True, to_dir=False, train_on_borders=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = execute_predict(model, imgs_test, stepsize=512, resize_shortest=True, extensive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('predictions.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix = confusion_matrix(pred, imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jaccard_foreground': 0.0,\n",
       " 'jaccard_background': 0.9996920171773659,\n",
       " 'voc_score': 0.49984600858868294,\n",
       " 'accuracy': 0.9996920171773659,\n",
       " 'precision': nan,\n",
       " 'recall': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics(cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_distribution(model, imgs_test, imgs_mask_test, extensive=True, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_curve(pred, imgs_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results On Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_train = False\n",
    "imgnr = 60\n",
    "input_img = cv2.imread('/n/regal/pfister_lab/vincent/vcasser/connectomics/movements/epfl-' + ('train' if use_train else 'test') + '-crop/' + str(imgnr) + '.png',0) \n",
    "gt = misc.imread('/n/regal/pfister_lab/vincent/vcasser/connectomics/movements/epfl-' + ('train' if use_train else 'test') + '-crop-mask/' + str(imgnr) + '.png')\n",
    "print(gt.shape)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(input_img, cmap='gray')\n",
    "\n",
    "print(input_img.shape)\n",
    "res = execute_predict(model, input_img.reshape(1,512,512,1).astype(float)/255.)\n",
    "print(res.min(), res.max())\n",
    "\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(res[0,:,:,0], cmap='gray')\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(gt[:,:,0], cmap='gray')\n",
    "\n",
    "cv2.imwrite('example_img_gt.png', gt)\n",
    "cv2.imwrite('example_img_raw.png', input_img)\n",
    "cv2.imwrite('example_img.png', res[0,:,:,0]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
