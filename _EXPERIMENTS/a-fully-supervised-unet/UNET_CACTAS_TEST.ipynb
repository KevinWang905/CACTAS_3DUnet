{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 09:43:16.552463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_management\n",
    "from data_management import load_stack\n",
    "from data_management import load_data\n",
    "\n",
    "import interactive_plot\n",
    "\n",
    "import metrics\n",
    "from metrics import statistics\n",
    "from metrics import confusion_matrix\n",
    "from metrics import error_distribution\n",
    "from metrics import error_borders\n",
    "from metrics import PR_curve\n",
    "\n",
    "import generator_extended\n",
    "\n",
    "import unet\n",
    "from unet import load_model_unet\n",
    "from unet import predict_net\n",
    "from unet import get_unet\n",
    "from unet import train\n",
    "from unet import execute_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATAPATH = '/raid/mpsych/CACTAS/DATA/Nathan Arnett Calcification/'\n",
    "images_file = os.path.join(DATAPATH, 'images_cropped.npy')\n",
    "labels_file = os.path.join(DATAPATH, 'labels_cropped.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float)\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    \n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = images[0:450]\n",
    "imgs_mask_train = labels[0:450]\n",
    "imgs_test = images[450:]\n",
    "imgs_mask_test = labels[450:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffa75615760>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_train[30],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffa6c103a00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_mask_train[30],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 256, 128, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_filters 16\n",
      "conv1 shape: (None, 256, 128, 16)\n",
      "conv1 shape: (None, 256, 128, 16)\n",
      "pool1 shape: (None, 128, 64, 16)\n",
      "conv2 shape: (None, 128, 64, 32)\n",
      "conv2 shape: (None, 128, 64, 32)\n",
      "pool2 shape: (None, 64, 32, 32)\n",
      "conv3 shape: (None, 64, 32, 64)\n",
      "conv3 shape: (None, 64, 32, 64)\n",
      "pool3 shape: (None, 32, 16, 64)\n",
      "using jaccard loss!\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(0.0001, imgs_train.shape[1], imgs_train.shape[2], dr_rate=0.2, diceloss=False, jaccardloss=True, \n",
    "                 focalloss=False, customloss=False, start_filters=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "data details:\n",
      "imgs_train.shape (450, 256, 128, 1)\n",
      "imgs_mask_train.shape (450, 256, 128, 1)\n",
      "imgs_test.shape (53, 256, 128, 1)\n",
      "imgs_mask_test.shape (53, 256, 128, 1)\n",
      "imgs_train.dtype float64\n",
      "imgs_mask_train.dtype float64\n",
      "imgs_test.dtype float64\n",
      "imgs_mask_test.dtype float64\n",
      "balance:\n",
      "train_total_px 14745600\n",
      "train_labeled_positive 27903\n",
      "train_fraction_positive 0.0018922932942708334\n",
      "min, max train 0.0 1.0\n",
      "train_total_px 14745600 number 0/1 in mask 14745600\n",
      "test_total_px 1736704\n",
      "test_labeled_positive 2658\n",
      "test_fraction_positive 0.0015304853331367925\n",
      "min, max test 0.0 1.0\n",
      "loading data done\n",
      "saving model checkpoints in /tmp/models/A100test/\n",
      "saving logfile in  /tmp/models/A100test/log.txt\n",
      "augmenting on the fly...\n",
      "computing statistics...\n",
      "<generator object train.<locals>.combine_generator at 0x7ffa6c282cf0>\n",
      "starting...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 10:13:03.522217: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-01-06 10:13:03.541172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245645000 Hz\n",
      "2023-01-06 10:13:18.984059: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-06 10:13:19.601581: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-01-06 10:13:20.311666: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2023-01-06 10:13:20.311692: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2023-01-06 10:13:20.311758: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-01-06 10:13:20.395831: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-06 10:13:21.195971: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ConcatOp : Dimensions of inputs should match: shape[0] = [50,128,64,64] vs. shape[1] = [50,128,32,16]\n\t [[node model_5/concatenate_27/concat (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:3063) ]] [Op:__inference_train_function_7371]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_5/concatenate_27/concat:\n model_5/dropout_16/dropout/Mul_1 (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/layers/core.py:208)\t\n model_5/conv2d_181/Relu (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:4700)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054533/370459007.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(model, imgs_train, imgs_mask_train, imgs_test, imgs_mask_test,\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0;34m'/tmp/models/A100test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       perform_flipping=True, perform_rotation=True, to_dir=False, train_on_borders=False)\n",
      "\u001b[0;32m~/Projects/CACTAS/_EXPERIMENTS/a-fully-supervised-unet/unet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, imgs_train, imgs_mask_train, imgs_test, imgs_mask_test, model_name, bt_size, train_epochs, iter_per_epoch, val_steps, finetune_path, perform_centering, perform_flipping, perform_rotation, perform_standardization, plot_graph, verbosity, to_dir, train_on_borders)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     model.fit_generator(train_generator,\n\u001b[0m\u001b[1;32m    169\u001b[0m                              \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1916\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1918\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  ConcatOp : Dimensions of inputs should match: shape[0] = [50,128,64,64] vs. shape[1] = [50,128,32,16]\n\t [[node model_5/concatenate_27/concat (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:3063) ]] [Op:__inference_train_function_7371]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_5/concatenate_27/concat:\n model_5/dropout_16/dropout/Mul_1 (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/layers/core.py:208)\t\n model_5/conv2d_181/Relu (defined at home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/keras/backend.py:4700)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "train(model, imgs_train, imgs_mask_train, imgs_test, imgs_mask_test,\n",
    "      '/tmp/models/A100test', 50, 1000, verbosity=1, \n",
    "      perform_flipping=True, perform_rotation=True, to_dir=False, train_on_borders=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = execute_predict(model, imgs_test, stepsize=512, resize_shortest=True, extensive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('predictions.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix = confusion_matrix(pred, imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jaccard_foreground': 0.0,\n",
       " 'jaccard_background': 0.9996920171773659,\n",
       " 'voc_score': 0.49984600858868294,\n",
       " 'accuracy': 0.9996920171773659,\n",
       " 'precision': nan,\n",
       " 'recall': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics(cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_distribution(model, imgs_test, imgs_mask_test, extensive=True, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_curve(pred, imgs_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results On Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_train = False\n",
    "imgnr = 60\n",
    "input_img = cv2.imread('/n/regal/pfister_lab/vincent/vcasser/connectomics/movements/epfl-' + ('train' if use_train else 'test') + '-crop/' + str(imgnr) + '.png',0) \n",
    "gt = misc.imread('/n/regal/pfister_lab/vincent/vcasser/connectomics/movements/epfl-' + ('train' if use_train else 'test') + '-crop-mask/' + str(imgnr) + '.png')\n",
    "print(gt.shape)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(input_img, cmap='gray')\n",
    "\n",
    "print(input_img.shape)\n",
    "res = execute_predict(model, input_img.reshape(1,512,512,1).astype(float)/255.)\n",
    "print(res.min(), res.max())\n",
    "\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(res[0,:,:,0], cmap='gray')\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.imshow(gt[:,:,0], cmap='gray')\n",
    "\n",
    "cv2.imwrite('example_img_gt.png', gt)\n",
    "cv2.imwrite('example_img_raw.png', input_img)\n",
    "cv2.imwrite('example_img.png', res[0,:,:,0]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
