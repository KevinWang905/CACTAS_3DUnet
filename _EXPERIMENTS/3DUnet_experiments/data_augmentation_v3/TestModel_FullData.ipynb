{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3136c0e6-71aa-41de-905e-4b1c102f344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 10:42:00.466509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-07 10:42:01.114440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "2.16.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import nrrd\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d89d3f-4439-46c5-b545-cab9f4bb676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoder_block(inputs, output_channels, lastlayer=False):\n",
    "    \"\"\"\n",
    "    Two 3x3x3 convolutions with batch normalization and ReLU activation\n",
    "    2x2x2 max pool\n",
    "    \"\"\"\n",
    "\n",
    "    # 3x3x3 convolutions with ReLU activation\n",
    "    x = tf.keras.layers.Conv3D(int(output_channels/2), kernel_size=3, strides=1, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(output_channels, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # 2x2x2 max pool\n",
    "\n",
    "    if not lastlayer:\n",
    "        x_maxPool = tf.keras.layers.MaxPool3D(pool_size=2, strides=2, padding = 'same')(x)\n",
    "    else:\n",
    "        x_maxPool = x\n",
    "\n",
    "    return x, x_maxPool\n",
    "\n",
    "def decoder_block(inputs, skip_features, output_channels):\n",
    "\n",
    "    # Upsampling with 2x2x2 filter\n",
    "    x = tf.keras.layers.Conv3DTranspose(output_channels*2, kernel_size=2, strides=2, padding = 'same')(inputs)\n",
    "\n",
    "# Concatenate the skip features\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_features])\n",
    "\n",
    "    # 2 convolutions with 3x3 filter, batch normalization, ReLU activation\n",
    "    x = tf.keras.layers.Conv3D(output_channels, kernel_size=3, strides=1, padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(output_channels, kernel_size=3, strides=1, padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def unet_3D():\n",
    "    inputs = tf.keras.Input(shape=(64, 64, 64, 1,))\n",
    "\n",
    "    e1_skip, e1_maxpool = encoder_block(inputs, 64)\n",
    "    e2_skip, e2_maxpool = encoder_block(e1_maxpool, 128)\n",
    "    e3_skip, e3_maxpool = encoder_block(e2_maxpool, 256)\n",
    "    _, e4 = encoder_block(e3_maxpool, 512, True)\n",
    "\n",
    "    decoder1 = decoder_block(e4, e3_skip, 256)\n",
    "    decoder2 = decoder_block(decoder1, e2_skip, 128)\n",
    "    decoder3 = decoder_block(decoder2, e1_skip, 64)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv3D(1, 1, strides = 1)(decoder3)\n",
    "    # outputs = tf.keras.layers.Conv3D(2, 1, strides = 1)(decoder3)\n",
    "    # outputs = tf.keras.layers.Reshape((64*64*64, 2))(outputs)\n",
    "    outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = inputs,  outputs = outputs,  name = 'Unet3D')\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42bec1ef-2247-4879-98b1-b365ce02e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth=0.000000001):\n",
    "    # yt = K.argmax(y_true, axis=2)\n",
    "    # yp = K.argmax(y_pred, axis=2)\n",
    "    # print(y_pred)\n",
    "    #yp = y_pred[0]\n",
    "    # yp[yp>=0.5]=1\n",
    "    # yp[yp<0.5]=0\n",
    "    yp = y_pred\n",
    "    yp = tf.where(yp >= 0.5, tf.ones_like(yp), yp)\n",
    "    yp = tf.where(yp < 0.5, tf.zeros_like(yp), yp)\n",
    "    yp = K.cast(yp, np.float32)\n",
    "\n",
    "    yt = K.cast(y_true, np.float32)\n",
    "\n",
    "    # print(yt.shape)\n",
    "    # print(yp.shape)\n",
    "    \n",
    "    intersection = K.sum(yt * yp)\n",
    "    union = K.sum(yt) + K.sum(yp)\n",
    "    # intersection = K.sum(yt * yp, axis=1)\n",
    "    # union = K.sum(yt, axis=1) + K.sum(yp, axis=1)\n",
    "    return (intersection + smooth) / (union-intersection+smooth)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3adb24-a202-454c-b34f-c71a3186ee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 10:42:01.837015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:65:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "model = unet_3D()\n",
    "# model.summary()\n",
    "\n",
    "print(\"compiling model\")\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='dice')#, metrics=[iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7429b2e4-5f74-4c54-9012-f46437589bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b08f6ab-61fb-4f71-9300-76882b15c7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512, 512, 211], [1, 311, 375, 179, 243, 27, 91], [2, 243, 307, 139, 203, 33, 97], [3, 209, 273, 143, 207, 40, 104], [4, 188, 252, 175, 239, 54, 118], [5, 220, 284, 175, 239, 66, 130], [6, 168, 232, 137, 201, 88, 152], [7, 311, 375, 145, 209, 90, 154], [8, 152, 216, 172, 236, 103, 167], [9, 186, 250, 175, 239, 118, 182], [10, 124, 188, 204, 268, 121, 185], [11, 328, 392, 177, 241, 122, 186], [12, 276, 340, 162, 226, 122, 186], [13, 173, 237, 207, 271, 129, 193]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Get Patch Coordinates\n",
    "\n",
    "with open(\"patch_coords.json\", 'r') as f:\n",
    "    p_coords = json.load(f)\n",
    "\n",
    "print(p_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7357c93e-4eb2-48fd-9969-759b5b4baf3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin.wang/miniconda3/envs/cactas/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 130 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 311, 375, 179, 243, 27, 91]\n",
      "[2, 243, 307, 139, 203, 33, 97]\n",
      "[3, 209, 273, 143, 207, 40, 104]\n",
      "[4, 188, 252, 175, 239, 54, 118]\n",
      "[5, 220, 284, 175, 239, 66, 130]\n",
      "[6, 168, 232, 137, 201, 88, 152]\n",
      "[7, 311, 375, 145, 209, 90, 154]\n",
      "[8, 152, 216, 172, 236, 103, 167]\n",
      "[9, 186, 250, 175, 239, 118, 182]\n",
      "[10, 124, 188, 204, 268, 121, 185]\n",
      "[11, 328, 392, 177, 241, 122, 186]\n",
      "[12, 276, 340, 162, 226, 122, 186]\n",
      "[13, 173, 237, 207, 271, 129, 193]\n"
     ]
    }
   ],
   "source": [
    "cp_number = \"{:04d}\".format(140)\n",
    "print(cp_number)\n",
    "model.load_weights(\"./checkpoints/cp-0140.weights.h5\")\n",
    "\n",
    "number = 18\n",
    "reformation = np.zeros(shape=(p_coords[0]))\n",
    "\n",
    "for patch in range(1, len(p_coords)):\n",
    "    print(p_coords[patch])    \n",
    "    try:\n",
    "        X, _ = nrrd.read(\"./test_data/inputs/18_volume_\"+str(p_coords[patch][0])+\".nrrd\")\n",
    "        X = np.array([X]).astype(np.float32)\n",
    "        X = np.expand_dims(X, -1)\n",
    "        \n",
    "        y = model.predict(X, verbose=0)\n",
    "        y = y[0]\n",
    "        y[y>=0.5]=1\n",
    "        y[y<0.5]=0\n",
    "        y = y[...,0]\n",
    "        print(y.shape)\n",
    "        reformation[p_coords[patch][1]:p_coords[patch][2], p_coords[patch][3]:p_coords[patch][4], p_coords[patch][5]:p_coords[patch][6]] += y\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "reformation[reformation > 1] = 1\n",
    "\n",
    "nrrd.write(\"./test_data/reform/predictions/\"+str(number)+\"_checkpoint_\"+str(cp_number)+\".nrrd\", reformation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c803eef-4034-471c-b429-9dce363144b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(reformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14514c17-4e24-4b90-936d-856db806fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(y_true, y_pred, smooth=0.000000001):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (intersection + smooth) / (union-intersection+smooth)\n",
    "    \n",
    "def f1_sens_prec(y_true, y_pred, smooth=0.000000001):\n",
    "    ones_matrix = np.ones(shape=(np.shape(y_true)))\n",
    "    yp_negatives = ones_matrix - y_pred\n",
    "    yt_negatives = ones_matrix - y_true\n",
    "    \n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fp = np.count_nonzero((y_pred-y_true) == 1)\n",
    "    tn = np.sum(yt_negatives * yp_negatives)\n",
    "    fn = np.count_nonzero((yp_negatives-yt_negatives) == 1)\n",
    "\n",
    "    fscore = (2 * tp) / (2*tp + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    return fscore, sensitivity, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1471cb3c-3f41-4bf1-8878-24da38dc6ada",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test_data/reform/predictions/18_gt.nrrd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnrrd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./test_data/reform/predictions/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_gt.nrrd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cactas/lib/python3.12/site-packages/nrrd/reader.py:515\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, custom_field_map, index_order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, custom_field_map: Optional[NRRDFieldMap] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, index_order: IndexOrder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[npt\u001b[38;5;241m.\u001b[39mNDArray, NRRDHeader]:\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a NRRD file and return the header and data\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    See :ref:`background/how-to-use:reading nrrd files` for more information on reading NRRD files.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m    :meth:`write`, :meth:`read_header`, :meth:`read_data`\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    516\u001b[0m         header \u001b[38;5;241m=\u001b[39m read_header(fh, custom_field_map)\n\u001b[1;32m    517\u001b[0m         data \u001b[38;5;241m=\u001b[39m read_data(header, fh, filename, index_order)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test_data/reform/predictions/18_gt.nrrd'"
     ]
    }
   ],
   "source": [
    "gt, _ = nrrd.read(\"./test_data/reform/predictions/\"+str(number)+\"_gt.nrrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95eedea3-28bf-48a4-af0a-df7b1200c224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6236559139784946, 0.5237020316027088, 0.770764119601329)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_iou(gt, reformation)\n",
    "f1_sens_prec(gt, reformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603ca301-aba3-48eb-9f3a-e797cac27954",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nrrd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m\n\u001b[1;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m gt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnrrd\u001b[49m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./test_data/reform/predictions/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(number)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_gt.nrrd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m best_cp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m best_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nrrd' is not defined"
     ]
    }
   ],
   "source": [
    "number = 18\n",
    "\n",
    "metrics = []\n",
    "\n",
    "gt, _ = nrrd.read(\"./test_data/reform/predictions/\"+str(number)+\"_gt.nrrd\")\n",
    "\n",
    "best_cp = 0\n",
    "best_iou = 0\n",
    "\n",
    "for cp in range(1, 10):\n",
    "    cp_number = \"{:04d}\".format(cp)\n",
    "    print(cp_number)\n",
    "    model.load_weights(\"./checkpoints/cp-\"+str(cp_number)+\".weights.h5\")\n",
    "    \n",
    "    reformation = np.zeros(shape=(p_coords[0]))\n",
    "    \n",
    "    for patch in range(1, len(p_coords)): \n",
    "        try:\n",
    "            X, _ = nrrd.read(\"./test_data/inputs/18_volume_\"+str(p_coords[patch][0])+\".nrrd\")\n",
    "            X = np.array([X]).astype(np.float32)\n",
    "            X = np.expand_dims(X, -1)\n",
    "            \n",
    "            y = model.predict(X, verbose=0)\n",
    "            y = y[0]\n",
    "            y[y>=0.5]=1\n",
    "            y[y<0.5]=0\n",
    "            y = y[...,0]\n",
    "            reformation[p_coords[patch][1]:p_coords[patch][2], p_coords[patch][3]:p_coords[patch][4], p_coords[patch][5]:p_coords[patch][6]] += y\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    reformation[reformation > 1] = 1\n",
    "    \n",
    "    nrrd.write(\"./test_data/reform/predictions/\"+str(number)+\"_checkpoint_\"+str(cp_number)+\".nrrd\", reformation)\n",
    "    iou = compute_iou(gt, reformation)\n",
    "    f1, sens, prec = f1_sens_prec(gt, reformation)\n",
    "    if iou > best_iou:\n",
    "        best_iou = iou\n",
    "        iou_other_metrics = [iou, f1, sens, prec]\n",
    "        best_cp = cp\n",
    "    print(\"IOU: \" + str(iou) + \", F1: \"+ str(f1) + \", Sensitivity: \" + str(sens) + \", Precision: \" + str(prec))\n",
    "    metrics.append([iou, f1, sens, prec])\n",
    "\n",
    "metrics_path = \"./test_data/reform/metrics/\"+str(number)+\".csv\"\n",
    "numpy.savetxt(\"data3.csv\", np.array(metrics),  delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2501e1d-9c0b-4272-af51-3484a369fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5712971481144699, 0.7271662763466042, 0.7009029345372461, 0.7554744525547445] 62\n"
     ]
    }
   ],
   "source": [
    "print(iou_other_metrics, best_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b074531-6fa8-46c9-a15b-192c2d46249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413a83a9-8892-4f08-a5ef-05b61c5a25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "metrics.append([1,2,3])\n",
    "metrics.append([4,5,6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d8c2e0e-c7ea-4db9-9298-5d32f153da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.csv\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331aeb5-640d-4dbe-ad4c-b86ca613c049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
