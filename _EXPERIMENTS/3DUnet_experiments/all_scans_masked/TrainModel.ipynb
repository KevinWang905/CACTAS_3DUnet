{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e68355e-43ca-4f33-8094-2ef4351500f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/kevin.wang/miniconda3/envs/tf-gpu-py310/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/kevin.wang/miniconda3/envs/cactas/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m185.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3136c0e6-71aa-41de-905e-4b1c102f344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 22:47:06.548372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-29 22:47:07.114507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "2.16.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d89d3f-4439-46c5-b545-cab9f4bb676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoder_block(inputs, output_channels, lastlayer=False):\n",
    "    \"\"\"\n",
    "    Two 3x3x3 convolutions with batch normalization and ReLU activation\n",
    "    2x2x2 max pool\n",
    "    \"\"\"\n",
    "\n",
    "    # 3x3x3 convolutions with ReLU activation\n",
    "    x = tf.keras.layers.Conv3D(int(output_channels/2), kernel_size=3, strides=1, padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(output_channels, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # 2x2x2 max pool\n",
    "\n",
    "    if not lastlayer:\n",
    "        x_maxPool = tf.keras.layers.MaxPool3D(pool_size=2, strides=2, padding = 'same')(x)\n",
    "    else:\n",
    "        x_maxPool = x\n",
    "\n",
    "    return x, x_maxPool\n",
    "\n",
    "def decoder_block(inputs, skip_features, output_channels):\n",
    "\n",
    "    # Upsampling with 2x2x2 filter\n",
    "    x = tf.keras.layers.Conv3DTranspose(output_channels*2, kernel_size=2, strides=2, padding = 'same')(inputs)\n",
    "\n",
    "# Concatenate the skip features\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_features])\n",
    "\n",
    "    # 2 convolutions with 3x3 filter, batch normalization, ReLU activation\n",
    "    x = tf.keras.layers.Conv3D(output_channels, kernel_size=3, strides=1, padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(output_channels, kernel_size=3, strides=1, padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def unet_3D():\n",
    "    inputs = tf.keras.Input(shape=(64, 64, 64, 1,))\n",
    "\n",
    "    e1_skip, e1_maxpool = encoder_block(inputs, 64)\n",
    "    e2_skip, e2_maxpool = encoder_block(e1_maxpool, 128)\n",
    "    e3_skip, e3_maxpool = encoder_block(e2_maxpool, 256)\n",
    "    _, e4 = encoder_block(e3_maxpool, 512, True)\n",
    "\n",
    "    decoder1 = decoder_block(e4, e3_skip, 256)\n",
    "    decoder2 = decoder_block(decoder1, e2_skip, 128)\n",
    "    decoder3 = decoder_block(decoder2, e1_skip, 64)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv3D(1, 1, strides = 1)(decoder3)\n",
    "    outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = inputs,  outputs = outputs,  name = 'Unet3D')\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bec1ef-2247-4879-98b1-b365ce02e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth=0.000000001):\n",
    "    # yt = K.argmax(y_true, axis=2)\n",
    "    # yp = K.argmax(y_pred, axis=2)\n",
    "    # print(y_pred)\n",
    "    #yp = y_pred[0]\n",
    "    # yp[yp>=0.5]=1\n",
    "    # yp[yp<0.5]=0\n",
    "    yp = y_pred\n",
    "    yp = tf.where(yp >= 0.5, tf.ones_like(yp), yp)\n",
    "    yp = tf.where(yp < 0.5, tf.zeros_like(yp), yp)\n",
    "    yp = K.cast(yp, np.float32)\n",
    "\n",
    "    yt = K.cast(y_true, np.float32)\n",
    "\n",
    "    # print(yt.shape)\n",
    "    # print(yp.shape)\n",
    "    \n",
    "    intersection = K.sum(yt * yp)\n",
    "    union = K.sum(yt) + K.sum(yp)\n",
    "    # intersection = K.sum(yt * yp, axis=1)\n",
    "    # union = K.sum(yt, axis=1) + K.sum(yp, axis=1)\n",
    "    return (intersection + smooth) / (union-intersection+smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3adb24-a202-454c-b34f-c71a3186ee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 22:47:10.557751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10089 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:65:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model = unet_3D()\n",
    "# model.summary()\n",
    "\n",
    "print(\"compiling model\")\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='dice', metrics=[iou])#, metrics=[iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1e7154-6c55-40d6-85ec-f1e7d45f0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = os.listdir(\"./gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8b82c8-2808-4103-b2d8-adabcb0098e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading inputs\n",
      "skipping 27_volume_90_aug_1.nrrd\n",
      "skipping 73_volume_130_aug_0.nrrd\n",
      "skipping 27_volume_139_aug_1.nrrd\n",
      "skipping 90_volume_69_aug_2.nrrd\n",
      "skipping 27_volume_95_aug_1.nrrd\n",
      "skipping 27_volume_56_aug_1.nrrd\n",
      "skipping 27_volume_45_aug_1.nrrd\n",
      "skipping 15_volume_70_aug_1.nrrd\n",
      "skipping 27_volume_64_aug_1.nrrd\n",
      "skipping 27_volume_97_aug_1.nrrd\n",
      "skipping 27_volume_130_aug_1.nrrd\n",
      "skipping 15_volume_3_aug_1.nrrd\n",
      "skipping 90_volume_9_aug_1.nrrd\n",
      "skipping 27_volume_117_aug_1.nrrd\n",
      "skipping 73_volume_38_aug_0.nrrd\n",
      "skipping 15_volume_53_aug_0.nrrd\n",
      "skipping 63_volume_10_aug_1.nrrd\n",
      "skipping 23_volume_12_aug_2.nrrd\n",
      "skipping 27_volume_3_aug_1.nrrd\n",
      "skipping 23_volume_1_aug_2.nrrd\n",
      "skipping 73_volume_58_aug_1.nrrd\n",
      "skipping 73_volume_75_aug_0.nrrd\n",
      "skipping 15_volume_54_aug_0.nrrd\n",
      "skipping 27_volume_121_aug_1.nrrd\n",
      "skipping 53_volume_18_aug_1.nrrd\n",
      "skipping 27_volume_148_aug_1.nrrd\n",
      "skipping 53_volume_16_aug_2.nrrd\n",
      "skipping 73_volume_123_aug_0.nrrd\n",
      "skipping 73_volume_76_aug_0.nrrd\n",
      "skipping 15_volume_1_aug_1.nrrd\n",
      "skipping 73_volume_125_aug_0.nrrd\n",
      "skipping 23_volume_29_aug_2.nrrd\n",
      "skipping 23_volume_25_aug_0.nrrd\n",
      "skipping 73_volume_29_aug_0.nrrd\n",
      "skipping 73_volume_27_aug_0.nrrd\n",
      "skipping 73_volume_64_aug_0.nrrd\n",
      "skipping 27_volume_134_aug_1.nrrd\n",
      "skipping 73_volume_115_aug_0.nrrd\n",
      "skipping 73_volume_49_aug_2.nrrd\n",
      "skipping 73_volume_106_aug_0.nrrd\n",
      "skipping 27_volume_63_aug_1.nrrd\n",
      "skipping 73_volume_28_aug_0.nrrd\n",
      "skipping 73_volume_71_aug_0.nrrd\n",
      "skipping 73_volume_82_aug_0.nrrd\n",
      "skipping 73_volume_129_aug_0.nrrd\n",
      "skipping 27_volume_103_aug_1.nrrd\n",
      "skipping 31_volume_10_aug_0.nrrd\n",
      "skipping 84_volume_4_aug_1.nrrd\n",
      "skipping 27_volume_120_aug_1.nrrd\n",
      "skipping 27_volume_91_aug_1.nrrd\n",
      "skipping 73_volume_58_aug_0.nrrd\n",
      "skipping 73_volume_57_aug_1.nrrd\n",
      "skipping 73_volume_49_aug_1.nrrd\n",
      "skipping 15_volume_4_aug_1.nrrd\n",
      "skipping 22_volume_20_aug_0.nrrd\n",
      "skipping 23_volume_17_aug_0.nrrd\n",
      "skipping 73_volume_84_aug_0.nrrd\n",
      "skipping 27_volume_49_aug_1.nrrd\n",
      "skipping 73_volume_98_aug_0.nrrd\n",
      "skipping 27_volume_132_aug_1.nrrd\n",
      "skipping 73_volume_124_aug_0.nrrd\n",
      "skipping 15_volume_62_aug_2.nrrd\n",
      "skipping 73_volume_95_aug_0.nrrd\n",
      "skipping 73_volume_72_aug_0.nrrd\n",
      "skipping 23_volume_25_aug_1.nrrd\n",
      "skipping 73_volume_109_aug_0.nrrd\n",
      "skipping 23_volume_52_aug_0.nrrd\n",
      "skipping 77_volume_52_aug_0.nrrd\n",
      "skipping 73_volume_45_aug_0.nrrd\n",
      "skipping 27_volume_116_aug_1.nrrd\n",
      "skipping 63_volume_12_aug_2.nrrd\n",
      "skipping 73_volume_53_aug_0.nrrd\n",
      "skipping 73_volume_35_aug_0.nrrd\n",
      "skipping 27_volume_75_aug_1.nrrd\n",
      "skipping 73_volume_61_aug_0.nrrd\n",
      "skipping 73_volume_90_aug_0.nrrd\n",
      "skipping 73_volume_97_aug_0.nrrd\n",
      "skipping 27_volume_59_aug_1.nrrd\n",
      "skipping 23_volume_26_aug_2.nrrd\n",
      "skipping 15_volume_52_aug_0.nrrd\n",
      "skipping 27_volume_100_aug_1.nrrd\n",
      "skipping 27_volume_108_aug_1.nrrd\n",
      "skipping 23_volume_34_aug_1.nrrd\n",
      "skipping 27_volume_61_aug_1.nrrd\n",
      "skipping 73_volume_69_aug_0.nrrd\n",
      "skipping 27_volume_147_aug_1.nrrd\n",
      "skipping 27_volume_34_aug_1.nrrd\n",
      "skipping 73_volume_44_aug_0.nrrd\n",
      "skipping 15_volume_16_aug_1.nrrd\n",
      "skipping 27_volume_40_aug_1.nrrd\n",
      "skipping 27_volume_93_aug_1.nrrd\n",
      "skipping 23_volume_33_aug_0.nrrd\n",
      "skipping 41_volume_18_aug_0.nrrd\n",
      "skipping 91_volume_10_aug_0.nrrd\n",
      "skipping 27_volume_123_aug_1.nrrd\n",
      "skipping 62_volume_3_aug_1.nrrd\n",
      "skipping 27_volume_99_aug_1.nrrd\n",
      "skipping 22_volume_19_aug_2.nrrd\n",
      "skipping 23_volume_6_aug_0.nrrd\n",
      "skipping 62_volume_18_aug_0.nrrd\n",
      "skipping 27_volume_146_aug_1.nrrd\n",
      "skipping 27_volume_163_aug_1.nrrd\n",
      "skipping 15_volume_63_aug_2.nrrd\n",
      "skipping 73_volume_61_aug_1.nrrd\n",
      "skipping 22_volume_21_aug_0.nrrd\n",
      "skipping 73_volume_88_aug_0.nrrd\n",
      "skipping 27_volume_111_aug_1.nrrd\n",
      "skipping 23_volume_26_aug_1.nrrd\n",
      "skipping 53_volume_15_aug_2.nrrd\n",
      "skipping 73_volume_120_aug_0.nrrd\n",
      "skipping 27_volume_83_aug_1.nrrd\n",
      "skipping 27_volume_124_aug_1.nrrd\n",
      "skipping 73_volume_65_aug_0.nrrd\n",
      "skipping 73_volume_60_aug_0.nrrd\n",
      "skipping 53_volume_9_aug_1.nrrd\n",
      "skipping 73_volume_111_aug_0.nrrd\n",
      "skipping 27_volume_138_aug_1.nrrd\n",
      "skipping 15_volume_71_aug_1.nrrd\n",
      "skipping 15_volume_38_aug_2.nrrd\n",
      "skipping 73_volume_112_aug_0.nrrd\n",
      "skipping 23_volume_19_aug_0.nrrd\n",
      "skipping 90_volume_36_aug_0.nrrd\n",
      "skipping 15_volume_56_aug_0.nrrd\n",
      "skipping 73_volume_83_aug_0.nrrd\n",
      "skipping 53_volume_15_aug_1.nrrd\n",
      "skipping 73_volume_121_aug_0.nrrd\n",
      "skipping 23_volume_38_aug_0.nrrd\n",
      "skipping 31_volume_10_aug_1.nrrd\n",
      "skipping 23_volume_37_aug_0.nrrd\n",
      "skipping 73_volume_34_aug_0.nrrd\n",
      "skipping 84_volume_7_aug_0.nrrd\n",
      "skipping 73_volume_93_aug_0.nrrd\n",
      "skipping 41_volume_17_aug_0.nrrd\n",
      "skipping 73_volume_128_aug_0.nrrd\n",
      "skipping 15_volume_25_aug_2.nrrd\n",
      "skipping 27_volume_33_aug_1.nrrd\n",
      "skipping 73_volume_81_aug_0.nrrd\n",
      "skipping 23_volume_27_aug_0.nrrd\n",
      "skipping 23_volume_32_aug_0.nrrd\n",
      "skipping 73_volume_12_aug_0.nrrd\n",
      "skipping 73_volume_102_aug_0.nrrd\n",
      "skipping 73_volume_96_aug_0.nrrd\n",
      "skipping 27_volume_128_aug_1.nrrd\n",
      "skipping 23_volume_30_aug_0.nrrd\n",
      "skipping 27_volume_81_aug_1.nrrd\n",
      "skipping 73_volume_104_aug_0.nrrd\n",
      "skipping 27_volume_23_aug_1.nrrd\n",
      "skipping 27_volume_96_aug_1.nrrd\n",
      "skipping 47_volume_18_aug_0.nrrd\n",
      "skipping 73_volume_1_aug_1.nrrd\n",
      "skipping 66_volume_1_aug_0.nrrd\n",
      "skipping 73_volume_47_aug_0.nrrd\n",
      "skipping 22_volume_18_aug_2.nrrd\n",
      "skipping 62_volume_2_aug_1.nrrd\n",
      "skipping 73_volume_49_aug_0.nrrd\n",
      "skipping 73_volume_79_aug_0.nrrd\n",
      "skipping 27_volume_110_aug_1.nrrd\n",
      "skipping 27_volume_150_aug_1.nrrd\n",
      "skipping 15_volume_25_aug_1.nrrd\n",
      "skipping 73_volume_131_aug_0.nrrd\n",
      "skipping 15_volume_2_aug_1.nrrd\n",
      "skipping 53_volume_20_aug_1.nrrd\n",
      "skipping 27_volume_19_aug_1.nrrd\n",
      "skipping 22_volume_17_aug_2.nrrd\n",
      "skipping 15_volume_55_aug_0.nrrd\n",
      "skipping 27_volume_142_aug_1.nrrd\n",
      "skipping 23_volume_31_aug_1.nrrd\n",
      "skipping 23_volume_1_aug_1.nrrd\n",
      "skipping 27_volume_46_aug_2.nrrd\n",
      "skipping 27_volume_137_aug_1.nrrd\n",
      "skipping 62_volume_1_aug_1.nrrd\n",
      "skipping 27_volume_109_aug_1.nrrd\n",
      "skipping 23_volume_35_aug_0.nrrd\n",
      "skipping 77_volume_49_aug_0.nrrd\n",
      "skipping 73_volume_126_aug_0.nrrd\n",
      "skipping 73_volume_48_aug_0.nrrd\n",
      "skipping 27_volume_131_aug_1.nrrd\n",
      "skipping 73_volume_54_aug_0.nrrd\n",
      "skipping 23_volume_36_aug_0.nrrd\n",
      "skipping 73_volume_30_aug_0.nrrd\n",
      "skipping 73_volume_2_aug_1.nrrd\n",
      "skipping 73_volume_67_aug_0.nrrd\n",
      "skipping 73_volume_110_aug_0.nrrd\n",
      "skipping 73_volume_39_aug_0.nrrd\n",
      "skipping 63_volume_8_aug_0.nrrd\n",
      "skipping 27_volume_114_aug_1.nrrd\n",
      "skipping 27_volume_133_aug_1.nrrd\n",
      "skipping 84_volume_6_aug_1.nrrd\n",
      "skipping 27_volume_6_aug_1.nrrd\n",
      "skipping 27_volume_71_aug_1.nrrd\n",
      "skipping 73_volume_70_aug_0.nrrd\n",
      "skipping 27_volume_149_aug_1.nrrd\n",
      "skipping 73_volume_103_aug_0.nrrd\n",
      "skipping 91_volume_9_aug_0.nrrd\n",
      "skipping 73_volume_122_aug_0.nrrd\n",
      "skipping 27_volume_105_aug_1.nrrd\n",
      "skipping 15_volume_30_aug_2.nrrd\n",
      "skipping 23_volume_36_aug_2.nrrd\n",
      "skipping 73_volume_74_aug_0.nrrd\n",
      "skipping 77_volume_7_aug_0.nrrd\n",
      "skipping 27_volume_57_aug_1.nrrd\n",
      "skipping 15_volume_64_aug_2.nrrd\n",
      "skipping 27_volume_129_aug_1.nrrd\n",
      "skipping 73_volume_21_aug_0.nrrd\n",
      "skipping 66_volume_8_aug_1.nrrd\n",
      "skipping 27_volume_153_aug_1.nrrd\n",
      "skipping 73_volume_80_aug_0.nrrd\n",
      "skipping 73_volume_23_aug_0.nrrd\n",
      "skipping 73_volume_114_aug_0.nrrd\n",
      "skipping 73_volume_113_aug_0.nrrd\n",
      "skipping 27_volume_74_aug_1.nrrd\n",
      "skipping 27_volume_22_aug_1.nrrd\n",
      "skipping 77_volume_51_aug_0.nrrd\n",
      "skipping 27_volume_41_aug_1.nrrd\n",
      "skipping 73_volume_66_aug_0.nrrd\n",
      "skipping 73_volume_127_aug_0.nrrd\n",
      "skipping 73_volume_50_aug_1.nrrd\n",
      "skipping 73_volume_13_aug_0.nrrd\n",
      "skipping 15_volume_32_aug_2.nrrd\n",
      "skipping 27_volume_85_aug_1.nrrd\n",
      "skipping 15_volume_39_aug_2.nrrd\n",
      "skipping 23_volume_18_aug_0.nrrd\n",
      "skipping 77_volume_3_aug_0.nrrd\n",
      "skipping 27_volume_27_aug_1.nrrd\n",
      "skipping 61_volume_10_aug_1.nrrd\n",
      "skipping 27_volume_53_aug_1.nrrd\n",
      "skipping 23_volume_29_aug_0.nrrd\n",
      "skipping 77_volume_48_aug_0.nrrd\n",
      "skipping 27_volume_122_aug_1.nrrd\n",
      "skipping 73_volume_59_aug_1.nrrd\n",
      "skipping 23_volume_19_aug_2.nrrd\n",
      "skipping 73_volume_73_aug_2.nrrd\n",
      "skipping 27_volume_104_aug_1.nrrd\n",
      "skipping 73_volume_91_aug_0.nrrd\n",
      "skipping 90_volume_44_aug_1.nrrd\n",
      "skipping 53_volume_13_aug_1.nrrd\n",
      "skipping 77_volume_53_aug_0.nrrd\n",
      "skipping 73_volume_20_aug_2.nrrd\n",
      "skipping 27_volume_102_aug_1.nrrd\n",
      "skipping 73_volume_59_aug_0.nrrd\n",
      "skipping 73_volume_20_aug_0.nrrd\n",
      "skipping 73_volume_105_aug_0.nrrd\n",
      "skipping 27_volume_32_aug_1.nrrd\n",
      "skipping 73_volume_107_aug_0.nrrd\n",
      "skipping 15_volume_41_aug_2.nrrd\n",
      "skipping 63_volume_11_aug_2.nrrd\n",
      "skipping 73_volume_60_aug_1.nrrd\n",
      "skipping 27_volume_143_aug_1.nrrd\n",
      "skipping 90_volume_47_aug_1.nrrd\n",
      "skipping 73_volume_29_aug_2.nrrd\n",
      "skipping 84_volume_7_aug_1.nrrd\n",
      "skipping 84_volume_5_aug_1.nrrd\n",
      "skipping 73_volume_108_aug_0.nrrd\n",
      "skipping 73_volume_55_aug_0.nrrd\n",
      "skipping 73_volume_40_aug_0.nrrd\n",
      "skipping 27_volume_112_aug_1.nrrd\n",
      "skipping 15_volume_35_aug_2.nrrd\n",
      "skipping 15_volume_27_aug_2.nrrd\n",
      "skipping 27_volume_50_aug_1.nrrd\n",
      "skipping 27_volume_82_aug_1.nrrd\n",
      "skipping 23_volume_26_aug_0.nrrd\n",
      "skipping 77_volume_50_aug_0.nrrd\n",
      "skipping 27_volume_101_aug_1.nrrd\n",
      "skipping 73_volume_3_aug_1.nrrd\n",
      "skipping 73_volume_36_aug_0.nrrd\n",
      "skipping 63_volume_13_aug_2.nrrd\n",
      "skipping 27_volume_162_aug_1.nrrd\n",
      "skipping 27_volume_48_aug_1.nrrd\n",
      "loading ground truths\n",
      "skipping 27_volume_90_aug_1.nrrd\n",
      "skipping 73_volume_130_aug_0.nrrd\n",
      "skipping 27_volume_139_aug_1.nrrd\n",
      "skipping 90_volume_69_aug_2.nrrd\n",
      "skipping 27_volume_95_aug_1.nrrd\n",
      "skipping 27_volume_56_aug_1.nrrd\n",
      "skipping 27_volume_45_aug_1.nrrd\n",
      "skipping 15_volume_70_aug_1.nrrd\n",
      "skipping 27_volume_64_aug_1.nrrd\n",
      "skipping 27_volume_97_aug_1.nrrd\n",
      "skipping 27_volume_130_aug_1.nrrd\n",
      "skipping 15_volume_3_aug_1.nrrd\n",
      "skipping 90_volume_9_aug_1.nrrd\n",
      "skipping 27_volume_117_aug_1.nrrd\n",
      "skipping 73_volume_38_aug_0.nrrd\n",
      "skipping 15_volume_53_aug_0.nrrd\n",
      "skipping 63_volume_10_aug_1.nrrd\n",
      "skipping 23_volume_12_aug_2.nrrd\n",
      "skipping 27_volume_3_aug_1.nrrd\n",
      "skipping 23_volume_1_aug_2.nrrd\n",
      "skipping 73_volume_58_aug_1.nrrd\n",
      "skipping 73_volume_75_aug_0.nrrd\n",
      "skipping 15_volume_54_aug_0.nrrd\n",
      "skipping 27_volume_121_aug_1.nrrd\n",
      "skipping 53_volume_18_aug_1.nrrd\n",
      "skipping 27_volume_148_aug_1.nrrd\n",
      "skipping 53_volume_16_aug_2.nrrd\n",
      "skipping 73_volume_123_aug_0.nrrd\n",
      "skipping 73_volume_76_aug_0.nrrd\n",
      "skipping 15_volume_1_aug_1.nrrd\n",
      "skipping 73_volume_125_aug_0.nrrd\n",
      "skipping 23_volume_29_aug_2.nrrd\n",
      "skipping 23_volume_25_aug_0.nrrd\n",
      "skipping 73_volume_29_aug_0.nrrd\n",
      "skipping 73_volume_27_aug_0.nrrd\n",
      "skipping 73_volume_64_aug_0.nrrd\n",
      "skipping 27_volume_134_aug_1.nrrd\n",
      "skipping 73_volume_115_aug_0.nrrd\n",
      "skipping 73_volume_49_aug_2.nrrd\n",
      "skipping 73_volume_106_aug_0.nrrd\n",
      "skipping 27_volume_63_aug_1.nrrd\n",
      "skipping 73_volume_28_aug_0.nrrd\n",
      "skipping 73_volume_71_aug_0.nrrd\n",
      "skipping 73_volume_82_aug_0.nrrd\n",
      "skipping 73_volume_129_aug_0.nrrd\n",
      "skipping 27_volume_103_aug_1.nrrd\n",
      "skipping 31_volume_10_aug_0.nrrd\n",
      "skipping 84_volume_4_aug_1.nrrd\n",
      "skipping 27_volume_120_aug_1.nrrd\n",
      "skipping 27_volume_91_aug_1.nrrd\n",
      "skipping 73_volume_58_aug_0.nrrd\n",
      "skipping 73_volume_57_aug_1.nrrd\n",
      "skipping 73_volume_49_aug_1.nrrd\n",
      "skipping 15_volume_4_aug_1.nrrd\n",
      "skipping 22_volume_20_aug_0.nrrd\n",
      "skipping 23_volume_17_aug_0.nrrd\n",
      "skipping 73_volume_84_aug_0.nrrd\n",
      "skipping 27_volume_49_aug_1.nrrd\n",
      "skipping 73_volume_98_aug_0.nrrd\n",
      "skipping 27_volume_132_aug_1.nrrd\n",
      "skipping 73_volume_124_aug_0.nrrd\n",
      "skipping 15_volume_62_aug_2.nrrd\n",
      "skipping 73_volume_95_aug_0.nrrd\n",
      "skipping 73_volume_72_aug_0.nrrd\n",
      "skipping 23_volume_25_aug_1.nrrd\n",
      "skipping 73_volume_109_aug_0.nrrd\n",
      "skipping 23_volume_52_aug_0.nrrd\n",
      "skipping 77_volume_52_aug_0.nrrd\n",
      "skipping 73_volume_45_aug_0.nrrd\n",
      "skipping 27_volume_116_aug_1.nrrd\n",
      "skipping 63_volume_12_aug_2.nrrd\n",
      "skipping 73_volume_53_aug_0.nrrd\n",
      "skipping 73_volume_35_aug_0.nrrd\n",
      "skipping 27_volume_75_aug_1.nrrd\n",
      "skipping 73_volume_61_aug_0.nrrd\n",
      "skipping 73_volume_90_aug_0.nrrd\n",
      "skipping 73_volume_97_aug_0.nrrd\n",
      "skipping 27_volume_59_aug_1.nrrd\n",
      "skipping 23_volume_26_aug_2.nrrd\n",
      "skipping 15_volume_52_aug_0.nrrd\n",
      "skipping 27_volume_100_aug_1.nrrd\n",
      "skipping 27_volume_108_aug_1.nrrd\n",
      "skipping 23_volume_34_aug_1.nrrd\n",
      "skipping 27_volume_61_aug_1.nrrd\n",
      "skipping 73_volume_69_aug_0.nrrd\n",
      "skipping 27_volume_147_aug_1.nrrd\n",
      "skipping 27_volume_34_aug_1.nrrd\n",
      "skipping 73_volume_44_aug_0.nrrd\n",
      "skipping 15_volume_16_aug_1.nrrd\n",
      "skipping 27_volume_40_aug_1.nrrd\n",
      "skipping 27_volume_93_aug_1.nrrd\n",
      "skipping 23_volume_33_aug_0.nrrd\n",
      "skipping 41_volume_18_aug_0.nrrd\n",
      "skipping 91_volume_10_aug_0.nrrd\n",
      "skipping 27_volume_123_aug_1.nrrd\n",
      "skipping 62_volume_3_aug_1.nrrd\n",
      "skipping 27_volume_99_aug_1.nrrd\n",
      "skipping 22_volume_19_aug_2.nrrd\n",
      "skipping 23_volume_6_aug_0.nrrd\n",
      "skipping 62_volume_18_aug_0.nrrd\n",
      "skipping 27_volume_146_aug_1.nrrd\n",
      "skipping 27_volume_163_aug_1.nrrd\n",
      "skipping 15_volume_63_aug_2.nrrd\n",
      "skipping 73_volume_61_aug_1.nrrd\n",
      "skipping 22_volume_21_aug_0.nrrd\n",
      "skipping 73_volume_88_aug_0.nrrd\n",
      "skipping 27_volume_111_aug_1.nrrd\n",
      "skipping 23_volume_26_aug_1.nrrd\n",
      "skipping 53_volume_15_aug_2.nrrd\n",
      "skipping 73_volume_120_aug_0.nrrd\n",
      "skipping 27_volume_83_aug_1.nrrd\n",
      "skipping 27_volume_124_aug_1.nrrd\n",
      "skipping 73_volume_65_aug_0.nrrd\n",
      "skipping 73_volume_60_aug_0.nrrd\n",
      "skipping 53_volume_9_aug_1.nrrd\n",
      "skipping 73_volume_111_aug_0.nrrd\n",
      "skipping 27_volume_138_aug_1.nrrd\n",
      "skipping 15_volume_71_aug_1.nrrd\n",
      "skipping 15_volume_38_aug_2.nrrd\n",
      "skipping 73_volume_112_aug_0.nrrd\n",
      "skipping 23_volume_19_aug_0.nrrd\n",
      "skipping 90_volume_36_aug_0.nrrd\n",
      "skipping 15_volume_56_aug_0.nrrd\n",
      "skipping 73_volume_83_aug_0.nrrd\n",
      "skipping 53_volume_15_aug_1.nrrd\n",
      "skipping 73_volume_121_aug_0.nrrd\n",
      "skipping 23_volume_38_aug_0.nrrd\n",
      "skipping 31_volume_10_aug_1.nrrd\n",
      "skipping 23_volume_37_aug_0.nrrd\n",
      "skipping 73_volume_34_aug_0.nrrd\n",
      "skipping 84_volume_7_aug_0.nrrd\n",
      "skipping 73_volume_93_aug_0.nrrd\n",
      "skipping 41_volume_17_aug_0.nrrd\n",
      "skipping 73_volume_128_aug_0.nrrd\n",
      "skipping 15_volume_25_aug_2.nrrd\n",
      "skipping 27_volume_33_aug_1.nrrd\n",
      "skipping 73_volume_81_aug_0.nrrd\n",
      "skipping 23_volume_27_aug_0.nrrd\n",
      "skipping 23_volume_32_aug_0.nrrd\n",
      "skipping 73_volume_12_aug_0.nrrd\n",
      "skipping 73_volume_102_aug_0.nrrd\n",
      "skipping 73_volume_96_aug_0.nrrd\n",
      "skipping 27_volume_128_aug_1.nrrd\n",
      "skipping 23_volume_30_aug_0.nrrd\n",
      "skipping 27_volume_81_aug_1.nrrd\n",
      "skipping 73_volume_104_aug_0.nrrd\n",
      "skipping 27_volume_23_aug_1.nrrd\n",
      "skipping 27_volume_96_aug_1.nrrd\n",
      "skipping 47_volume_18_aug_0.nrrd\n",
      "skipping 73_volume_1_aug_1.nrrd\n",
      "skipping 66_volume_1_aug_0.nrrd\n",
      "skipping 73_volume_47_aug_0.nrrd\n",
      "skipping 22_volume_18_aug_2.nrrd\n",
      "skipping 62_volume_2_aug_1.nrrd\n",
      "skipping 73_volume_49_aug_0.nrrd\n",
      "skipping 73_volume_79_aug_0.nrrd\n",
      "skipping 27_volume_110_aug_1.nrrd\n",
      "skipping 27_volume_150_aug_1.nrrd\n",
      "skipping 15_volume_25_aug_1.nrrd\n",
      "skipping 73_volume_131_aug_0.nrrd\n",
      "skipping 15_volume_2_aug_1.nrrd\n",
      "skipping 53_volume_20_aug_1.nrrd\n",
      "skipping 27_volume_19_aug_1.nrrd\n",
      "skipping 22_volume_17_aug_2.nrrd\n",
      "skipping 15_volume_55_aug_0.nrrd\n",
      "skipping 27_volume_142_aug_1.nrrd\n",
      "skipping 23_volume_31_aug_1.nrrd\n",
      "skipping 23_volume_1_aug_1.nrrd\n",
      "skipping 27_volume_46_aug_2.nrrd\n",
      "skipping 27_volume_137_aug_1.nrrd\n",
      "skipping 62_volume_1_aug_1.nrrd\n",
      "skipping 27_volume_109_aug_1.nrrd\n",
      "skipping 23_volume_35_aug_0.nrrd\n",
      "skipping 77_volume_49_aug_0.nrrd\n",
      "skipping 73_volume_126_aug_0.nrrd\n",
      "skipping 73_volume_48_aug_0.nrrd\n",
      "skipping 27_volume_131_aug_1.nrrd\n",
      "skipping 73_volume_54_aug_0.nrrd\n",
      "skipping 23_volume_36_aug_0.nrrd\n",
      "skipping 73_volume_30_aug_0.nrrd\n",
      "skipping 73_volume_2_aug_1.nrrd\n",
      "skipping 73_volume_67_aug_0.nrrd\n",
      "skipping 73_volume_110_aug_0.nrrd\n",
      "skipping 73_volume_39_aug_0.nrrd\n",
      "skipping 63_volume_8_aug_0.nrrd\n",
      "skipping 27_volume_114_aug_1.nrrd\n",
      "skipping 27_volume_133_aug_1.nrrd\n",
      "skipping 84_volume_6_aug_1.nrrd\n",
      "skipping 27_volume_6_aug_1.nrrd\n",
      "skipping 27_volume_71_aug_1.nrrd\n",
      "skipping 73_volume_70_aug_0.nrrd\n",
      "skipping 27_volume_149_aug_1.nrrd\n",
      "skipping 73_volume_103_aug_0.nrrd\n",
      "skipping 91_volume_9_aug_0.nrrd\n",
      "skipping 73_volume_122_aug_0.nrrd\n",
      "skipping 27_volume_105_aug_1.nrrd\n",
      "skipping 15_volume_30_aug_2.nrrd\n",
      "skipping 23_volume_36_aug_2.nrrd\n",
      "skipping 73_volume_74_aug_0.nrrd\n",
      "skipping 77_volume_7_aug_0.nrrd\n",
      "skipping 27_volume_57_aug_1.nrrd\n",
      "skipping 15_volume_64_aug_2.nrrd\n",
      "skipping 27_volume_129_aug_1.nrrd\n",
      "skipping 73_volume_21_aug_0.nrrd\n",
      "skipping 66_volume_8_aug_1.nrrd\n",
      "skipping 27_volume_153_aug_1.nrrd\n",
      "skipping 73_volume_80_aug_0.nrrd\n",
      "skipping 73_volume_23_aug_0.nrrd\n",
      "skipping 73_volume_114_aug_0.nrrd\n",
      "skipping 73_volume_113_aug_0.nrrd\n",
      "skipping 27_volume_74_aug_1.nrrd\n",
      "skipping 27_volume_22_aug_1.nrrd\n",
      "skipping 77_volume_51_aug_0.nrrd\n",
      "skipping 27_volume_41_aug_1.nrrd\n",
      "skipping 73_volume_66_aug_0.nrrd\n",
      "skipping 73_volume_127_aug_0.nrrd\n",
      "skipping 73_volume_50_aug_1.nrrd\n",
      "skipping 73_volume_13_aug_0.nrrd\n",
      "skipping 15_volume_32_aug_2.nrrd\n",
      "skipping 27_volume_85_aug_1.nrrd\n",
      "skipping 15_volume_39_aug_2.nrrd\n",
      "skipping 23_volume_18_aug_0.nrrd\n",
      "skipping 77_volume_3_aug_0.nrrd\n",
      "skipping 27_volume_27_aug_1.nrrd\n",
      "skipping 61_volume_10_aug_1.nrrd\n",
      "skipping 27_volume_53_aug_1.nrrd\n",
      "skipping 23_volume_29_aug_0.nrrd\n",
      "skipping 77_volume_48_aug_0.nrrd\n",
      "skipping 27_volume_122_aug_1.nrrd\n",
      "skipping 73_volume_59_aug_1.nrrd\n",
      "skipping 23_volume_19_aug_2.nrrd\n",
      "skipping 73_volume_73_aug_2.nrrd\n",
      "skipping 27_volume_104_aug_1.nrrd\n",
      "skipping 73_volume_91_aug_0.nrrd\n",
      "skipping 90_volume_44_aug_1.nrrd\n",
      "skipping 53_volume_13_aug_1.nrrd\n",
      "skipping 77_volume_53_aug_0.nrrd\n",
      "skipping 73_volume_20_aug_2.nrrd\n",
      "skipping 27_volume_102_aug_1.nrrd\n",
      "skipping 73_volume_59_aug_0.nrrd\n",
      "skipping 73_volume_20_aug_0.nrrd\n",
      "skipping 73_volume_105_aug_0.nrrd\n",
      "skipping 27_volume_32_aug_1.nrrd\n",
      "skipping 73_volume_107_aug_0.nrrd\n",
      "skipping 15_volume_41_aug_2.nrrd\n",
      "skipping 63_volume_11_aug_2.nrrd\n",
      "skipping 73_volume_60_aug_1.nrrd\n",
      "skipping 27_volume_143_aug_1.nrrd\n",
      "skipping 90_volume_47_aug_1.nrrd\n",
      "skipping 73_volume_29_aug_2.nrrd\n",
      "skipping 84_volume_7_aug_1.nrrd\n",
      "skipping 84_volume_5_aug_1.nrrd\n",
      "skipping 73_volume_108_aug_0.nrrd\n",
      "skipping 73_volume_55_aug_0.nrrd\n",
      "skipping 73_volume_40_aug_0.nrrd\n",
      "skipping 27_volume_112_aug_1.nrrd\n",
      "skipping 15_volume_35_aug_2.nrrd\n",
      "skipping 15_volume_27_aug_2.nrrd\n",
      "skipping 27_volume_50_aug_1.nrrd\n",
      "skipping 27_volume_82_aug_1.nrrd\n",
      "skipping 23_volume_26_aug_0.nrrd\n",
      "skipping 77_volume_50_aug_0.nrrd\n",
      "skipping 27_volume_101_aug_1.nrrd\n",
      "skipping 73_volume_3_aug_1.nrrd\n",
      "skipping 73_volume_36_aug_0.nrrd\n",
      "skipping 63_volume_13_aug_2.nrrd\n",
      "skipping 27_volume_162_aug_1.nrrd\n",
      "skipping 27_volume_48_aug_1.nrrd\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "print(\"loading inputs\")\n",
    "\n",
    "number_inputs = len(trainlist)\n",
    "\n",
    "X, _ =  nrrd.read(\"inputs/\" + trainlist[0])\n",
    "X = np.array([X]).astype(np.float32)\n",
    "X = np.expand_dims(X, -1)\n",
    "for i in range(1, number_inputs):\n",
    "\n",
    "    try:\n",
    "        volume, _ =  nrrd.read(\"inputs/\" + trainlist[i])\n",
    "        volume = np.array([volume])\n",
    "        volume = np.expand_dims(volume, -1)\n",
    "        X = np.concatenate((X, volume), axis=0)\n",
    "    except:\n",
    "        print(\"skipping \" + trainlist[i])\n",
    "\n",
    "print(\"loading ground truths\")\n",
    "\n",
    "valid_samples = [trainlist[0]]\n",
    "\n",
    "y, _ =  nrrd.read(\"gt/\" + trainlist[0])\n",
    "y = np.array([y])\n",
    "y = np.expand_dims(y, axis=-1)\n",
    "\n",
    "for i in range(1, number_inputs):\n",
    "    try:\n",
    "        volume, _ =  nrrd.read(\"gt/\" + trainlist[i])\n",
    "        volume = np.array([volume])\n",
    "        volume = np.expand_dims(volume, axis=-1)\n",
    "        y = np.concatenate((y, volume), axis=0)\n",
    "        valid_samples.append(trainlist[i])\n",
    "    except:\n",
    "        print(\"skipping \" + trainlist[i])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02cc4a2-5c9e-4032-8f3d-8a644c19256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- fitting model ---------------------\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719720897.809471    5489 service.cc:145] XLA service 0x7bc8940340f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1719720897.809519    5489 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "2024-06-30 00:14:57.991202: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-30 00:14:58.760960: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/1915\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:28:32\u001b[0m 25s/step - iou: 2.6013e-15 - loss: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1719720917.120235    5489 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - iou: 0.0778 - loss: 0.9911\n",
      "Epoch 1: saving model to ./checkpoints/cp-0001.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 161ms/step - iou: 0.0778 - loss: 0.9910 - val_iou: 0.1250 - val_loss: 0.9670\n",
      "Epoch 2/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.0931 - loss: 0.9540\n",
      "Epoch 2: saving model to ./checkpoints/cp-0002.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.0931 - loss: 0.9540 - val_iou: 0.1005 - val_loss: 0.9422\n",
      "Epoch 3/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1209 - loss: 0.9316\n",
      "Epoch 3: saving model to ./checkpoints/cp-0003.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1209 - loss: 0.9316 - val_iou: 0.1851 - val_loss: 0.9422\n",
      "Epoch 4/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1069 - loss: 0.9210\n",
      "Epoch 4: saving model to ./checkpoints/cp-0004.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1069 - loss: 0.9210 - val_iou: 0.3003 - val_loss: 0.9339\n",
      "Epoch 5/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.0862 - loss: 0.9213\n",
      "Epoch 5: saving model to ./checkpoints/cp-0005.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.0862 - loss: 0.9213 - val_iou: 0.1776 - val_loss: 0.9393\n",
      "Epoch 6/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1043 - loss: 0.9120\n",
      "Epoch 6: saving model to ./checkpoints/cp-0006.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1042 - loss: 0.9120 - val_iou: 0.3713 - val_loss: 0.9259\n",
      "Epoch 7/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1042 - loss: 0.9116\n",
      "Epoch 7: saving model to ./checkpoints/cp-0007.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1042 - loss: 0.9116 - val_iou: 0.2163 - val_loss: 0.9373\n",
      "Epoch 8/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1090 - loss: 0.9082\n",
      "Epoch 8: saving model to ./checkpoints/cp-0008.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1090 - loss: 0.9082 - val_iou: 0.1803 - val_loss: 0.9271\n",
      "Epoch 9/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.0964 - loss: 0.9062\n",
      "Epoch 9: saving model to ./checkpoints/cp-0009.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.0964 - loss: 0.9062 - val_iou: 0.2275 - val_loss: 0.9034\n",
      "Epoch 10/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1562 - loss: 0.8875\n",
      "Epoch 10: saving model to ./checkpoints/cp-0010.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1562 - loss: 0.8875 - val_iou: 0.2455 - val_loss: 0.9215\n",
      "Epoch 11/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1777 - loss: 0.8883\n",
      "Epoch 11: saving model to ./checkpoints/cp-0011.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1777 - loss: 0.8883 - val_iou: 0.5482 - val_loss: 0.9498\n",
      "Epoch 12/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2344 - loss: 0.8883\n",
      "Epoch 12: saving model to ./checkpoints/cp-0012.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.2344 - loss: 0.8883 - val_iou: 0.5244 - val_loss: 0.9039\n",
      "Epoch 13/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.1613 - loss: 0.8945\n",
      "Epoch 13: saving model to ./checkpoints/cp-0013.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.1613 - loss: 0.8945 - val_iou: 0.2850 - val_loss: 0.9148\n",
      "Epoch 14/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2160 - loss: 0.8753\n",
      "Epoch 14: saving model to ./checkpoints/cp-0014.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.2160 - loss: 0.8753 - val_iou: 0.3371 - val_loss: 0.9030\n",
      "Epoch 15/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2207 - loss: 0.8677\n",
      "Epoch 15: saving model to ./checkpoints/cp-0015.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.2207 - loss: 0.8677 - val_iou: 0.0860 - val_loss: 0.9298\n",
      "Epoch 16/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2150 - loss: 0.8717\n",
      "Epoch 16: saving model to ./checkpoints/cp-0016.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.2150 - loss: 0.8717 - val_iou: 0.4529 - val_loss: 0.9060\n",
      "Epoch 17/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2678 - loss: 0.8647\n",
      "Epoch 17: saving model to ./checkpoints/cp-0017.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.2678 - loss: 0.8647 - val_iou: 0.3515 - val_loss: 0.8960\n",
      "Epoch 18/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3205 - loss: 0.8665\n",
      "Epoch 18: saving model to ./checkpoints/cp-0018.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3205 - loss: 0.8665 - val_iou: 0.3437 - val_loss: 0.8889\n",
      "Epoch 19/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2435 - loss: 0.8581\n",
      "Epoch 19: saving model to ./checkpoints/cp-0019.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.2435 - loss: 0.8581 - val_iou: 0.1455 - val_loss: 0.9000\n",
      "Epoch 20/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2356 - loss: 0.8536\n",
      "Epoch 20: saving model to ./checkpoints/cp-0020.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.2356 - loss: 0.8536 - val_iou: 0.3752 - val_loss: 0.8971\n",
      "Epoch 21/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3602 - loss: 0.8575\n",
      "Epoch 21: saving model to ./checkpoints/cp-0021.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3602 - loss: 0.8575 - val_iou: 0.4790 - val_loss: 0.8802\n",
      "Epoch 22/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3528 - loss: 0.8554\n",
      "Epoch 22: saving model to ./checkpoints/cp-0022.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3528 - loss: 0.8554 - val_iou: 0.5426 - val_loss: 0.9043\n",
      "Epoch 23/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3085 - loss: 0.8564\n",
      "Epoch 23: saving model to ./checkpoints/cp-0023.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3085 - loss: 0.8564 - val_iou: 0.3234 - val_loss: 0.8888\n",
      "Epoch 24/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.2847 - loss: 0.8415\n",
      "Epoch 24: saving model to ./checkpoints/cp-0024.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.2847 - loss: 0.8415 - val_iou: 0.3495 - val_loss: 0.8821\n",
      "Epoch 25/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3719 - loss: 0.8424\n",
      "Epoch 25: saving model to ./checkpoints/cp-0025.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3719 - loss: 0.8424 - val_iou: 0.4457 - val_loss: 0.8674\n",
      "Epoch 26/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3268 - loss: 0.8431\n",
      "Epoch 26: saving model to ./checkpoints/cp-0026.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.3268 - loss: 0.8431 - val_iou: 0.6039 - val_loss: 0.8986\n",
      "Epoch 27/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3312 - loss: 0.8351\n",
      "Epoch 27: saving model to ./checkpoints/cp-0027.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.3312 - loss: 0.8351 - val_iou: 0.5908 - val_loss: 0.8785\n",
      "Epoch 28/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4031 - loss: 0.8428\n",
      "Epoch 28: saving model to ./checkpoints/cp-0028.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4031 - loss: 0.8428 - val_iou: 0.5738 - val_loss: 0.9194\n",
      "Epoch 29/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3893 - loss: 0.8444\n",
      "Epoch 29: saving model to ./checkpoints/cp-0029.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3893 - loss: 0.8444 - val_iou: 0.4951 - val_loss: 0.8636\n",
      "Epoch 30/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3735 - loss: 0.8305\n",
      "Epoch 30: saving model to ./checkpoints/cp-0030.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3735 - loss: 0.8305 - val_iou: 0.0848 - val_loss: 0.9127\n",
      "Epoch 31/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3682 - loss: 0.8213\n",
      "Epoch 31: saving model to ./checkpoints/cp-0031.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3682 - loss: 0.8213 - val_iou: 0.4502 - val_loss: 0.8839\n",
      "Epoch 32/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3049 - loss: 0.8356\n",
      "Epoch 32: saving model to ./checkpoints/cp-0032.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3049 - loss: 0.8356 - val_iou: 0.4942 - val_loss: 0.8590\n",
      "Epoch 33/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3192 - loss: 0.8303\n",
      "Epoch 33: saving model to ./checkpoints/cp-0033.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3192 - loss: 0.8303 - val_iou: 0.5994 - val_loss: 0.8574\n",
      "Epoch 34/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4207 - loss: 0.8311\n",
      "Epoch 34: saving model to ./checkpoints/cp-0034.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4206 - loss: 0.8311 - val_iou: 0.5760 - val_loss: 0.8550\n",
      "Epoch 35/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3713 - loss: 0.8251\n",
      "Epoch 35: saving model to ./checkpoints/cp-0035.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3713 - loss: 0.8251 - val_iou: 0.6193 - val_loss: 0.9044\n",
      "Epoch 36/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4257 - loss: 0.8100\n",
      "Epoch 36: saving model to ./checkpoints/cp-0036.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4256 - loss: 0.8101 - val_iou: 0.5966 - val_loss: 0.8425\n",
      "Epoch 37/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4300 - loss: 0.8227\n",
      "Epoch 37: saving model to ./checkpoints/cp-0037.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4301 - loss: 0.8227 - val_iou: 0.5657 - val_loss: 0.8743\n",
      "Epoch 38/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3950 - loss: 0.8230\n",
      "Epoch 38: saving model to ./checkpoints/cp-0038.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.3950 - loss: 0.8230 - val_iou: 0.5759 - val_loss: 0.8769\n",
      "Epoch 39/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4032 - loss: 0.8309\n",
      "Epoch 39: saving model to ./checkpoints/cp-0039.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4032 - loss: 0.8309 - val_iou: 0.5255 - val_loss: 0.8490\n",
      "Epoch 40/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3990 - loss: 0.8077\n",
      "Epoch 40: saving model to ./checkpoints/cp-0040.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3990 - loss: 0.8077 - val_iou: 0.6061 - val_loss: 0.8809\n",
      "Epoch 41/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4341 - loss: 0.8233\n",
      "Epoch 41: saving model to ./checkpoints/cp-0041.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4341 - loss: 0.8233 - val_iou: 0.0802 - val_loss: 0.9254\n",
      "Epoch 42/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4570 - loss: 0.8070\n",
      "Epoch 42: saving model to ./checkpoints/cp-0042.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4570 - loss: 0.8070 - val_iou: 0.5807 - val_loss: 0.8796\n",
      "Epoch 43/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3852 - loss: 0.8111\n",
      "Epoch 43: saving model to ./checkpoints/cp-0043.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3852 - loss: 0.8111 - val_iou: 0.4434 - val_loss: 0.9108\n",
      "Epoch 44/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4266 - loss: 0.8210\n",
      "Epoch 44: saving model to ./checkpoints/cp-0044.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4266 - loss: 0.8210 - val_iou: 0.5605 - val_loss: 0.8873\n",
      "Epoch 45/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4110 - loss: 0.8143\n",
      "Epoch 45: saving model to ./checkpoints/cp-0045.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4110 - loss: 0.8143 - val_iou: 0.6082 - val_loss: 0.8585\n",
      "Epoch 46/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4959 - loss: 0.8149\n",
      "Epoch 46: saving model to ./checkpoints/cp-0046.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4959 - loss: 0.8149 - val_iou: 0.6074 - val_loss: 0.8960\n",
      "Epoch 47/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4190 - loss: 0.8234\n",
      "Epoch 47: saving model to ./checkpoints/cp-0047.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4190 - loss: 0.8234 - val_iou: 0.6059 - val_loss: 0.8783\n",
      "Epoch 48/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - iou: 0.4477 - loss: 0.8159\n",
      "Epoch 48: saving model to ./checkpoints/cp-0048.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 154ms/step - iou: 0.4477 - loss: 0.8159 - val_iou: 0.5905 - val_loss: 0.8613\n",
      "Epoch 49/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4715 - loss: 0.8042\n",
      "Epoch 49: saving model to ./checkpoints/cp-0049.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 154ms/step - iou: 0.4715 - loss: 0.8042 - val_iou: 0.5967 - val_loss: 0.8457\n",
      "Epoch 50/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4610 - loss: 0.8118\n",
      "Epoch 50: saving model to ./checkpoints/cp-0050.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4610 - loss: 0.8118 - val_iou: 0.6363 - val_loss: 0.8625\n",
      "Epoch 51/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5282 - loss: 0.8016\n",
      "Epoch 51: saving model to ./checkpoints/cp-0051.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5282 - loss: 0.8016 - val_iou: 0.5598 - val_loss: 0.8587\n",
      "Epoch 52/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5148 - loss: 0.7987\n",
      "Epoch 52: saving model to ./checkpoints/cp-0052.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5148 - loss: 0.7987 - val_iou: 0.4652 - val_loss: 0.8778\n",
      "Epoch 53/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5669 - loss: 0.8066\n",
      "Epoch 53: saving model to ./checkpoints/cp-0053.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5669 - loss: 0.8066 - val_iou: 0.5672 - val_loss: 0.8332\n",
      "Epoch 54/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4720 - loss: 0.8019\n",
      "Epoch 54: saving model to ./checkpoints/cp-0054.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4720 - loss: 0.8019 - val_iou: 0.6773 - val_loss: 0.9024\n",
      "Epoch 55/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5053 - loss: 0.8238\n",
      "Epoch 55: saving model to ./checkpoints/cp-0055.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5053 - loss: 0.8238 - val_iou: 0.6175 - val_loss: 0.9229\n",
      "Epoch 56/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5287 - loss: 0.8084\n",
      "Epoch 56: saving model to ./checkpoints/cp-0056.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5287 - loss: 0.8084 - val_iou: 0.6250 - val_loss: 0.8755\n",
      "Epoch 57/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4846 - loss: 0.8184\n",
      "Epoch 57: saving model to ./checkpoints/cp-0057.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4846 - loss: 0.8184 - val_iou: 0.1248 - val_loss: 0.8956\n",
      "Epoch 58/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.3615 - loss: 0.8094\n",
      "Epoch 58: saving model to ./checkpoints/cp-0058.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.3616 - loss: 0.8094 - val_iou: 0.5621 - val_loss: 0.8486\n",
      "Epoch 59/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5276 - loss: 0.7893\n",
      "Epoch 59: saving model to ./checkpoints/cp-0059.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.5276 - loss: 0.7893 - val_iou: 0.5326 - val_loss: 0.8284\n",
      "Epoch 60/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5164 - loss: 0.8098\n",
      "Epoch 60: saving model to ./checkpoints/cp-0060.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5164 - loss: 0.8098 - val_iou: 0.6549 - val_loss: 0.9321\n",
      "Epoch 61/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5153 - loss: 0.8102\n",
      "Epoch 61: saving model to ./checkpoints/cp-0061.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5153 - loss: 0.8102 - val_iou: 0.5941 - val_loss: 0.8781\n",
      "Epoch 62/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5415 - loss: 0.7972\n",
      "Epoch 62: saving model to ./checkpoints/cp-0062.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5415 - loss: 0.7972 - val_iou: 0.6031 - val_loss: 0.8881\n",
      "Epoch 63/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5880 - loss: 0.7978\n",
      "Epoch 63: saving model to ./checkpoints/cp-0063.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5880 - loss: 0.7978 - val_iou: 0.5551 - val_loss: 0.8954\n",
      "Epoch 64/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5802 - loss: 0.8062\n",
      "Epoch 64: saving model to ./checkpoints/cp-0064.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5802 - loss: 0.8062 - val_iou: 0.6329 - val_loss: 0.8750\n",
      "Epoch 65/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6174 - loss: 0.8056\n",
      "Epoch 65: saving model to ./checkpoints/cp-0065.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6174 - loss: 0.8056 - val_iou: 0.5963 - val_loss: 0.8486\n",
      "Epoch 66/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5425 - loss: 0.7948\n",
      "Epoch 66: saving model to ./checkpoints/cp-0066.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.5425 - loss: 0.7948 - val_iou: 0.6171 - val_loss: 0.8587\n",
      "Epoch 67/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5343 - loss: 0.8116\n",
      "Epoch 67: saving model to ./checkpoints/cp-0067.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5342 - loss: 0.8116 - val_iou: 0.5591 - val_loss: 0.8327\n",
      "Epoch 68/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5261 - loss: 0.7960\n",
      "Epoch 68: saving model to ./checkpoints/cp-0068.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5261 - loss: 0.7960 - val_iou: 0.5976 - val_loss: 0.8489\n",
      "Epoch 69/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5885 - loss: 0.7991\n",
      "Epoch 69: saving model to ./checkpoints/cp-0069.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5885 - loss: 0.7991 - val_iou: 0.6223 - val_loss: 0.8620\n",
      "Epoch 70/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5937 - loss: 0.7948\n",
      "Epoch 70: saving model to ./checkpoints/cp-0070.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5937 - loss: 0.7948 - val_iou: 0.5414 - val_loss: 0.8854\n",
      "Epoch 71/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5314 - loss: 0.7974\n",
      "Epoch 71: saving model to ./checkpoints/cp-0071.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5314 - loss: 0.7974 - val_iou: 0.6590 - val_loss: 0.8391\n",
      "Epoch 72/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5090 - loss: 0.7973\n",
      "Epoch 72: saving model to ./checkpoints/cp-0072.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5090 - loss: 0.7973 - val_iou: 0.6573 - val_loss: 0.8440\n",
      "Epoch 73/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5935 - loss: 0.7907\n",
      "Epoch 73: saving model to ./checkpoints/cp-0073.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5935 - loss: 0.7907 - val_iou: 0.4919 - val_loss: 0.9227\n",
      "Epoch 74/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5392 - loss: 0.8000\n",
      "Epoch 74: saving model to ./checkpoints/cp-0074.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5392 - loss: 0.8000 - val_iou: 0.6390 - val_loss: 0.8533\n",
      "Epoch 75/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5760 - loss: 0.7924\n",
      "Epoch 75: saving model to ./checkpoints/cp-0075.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5760 - loss: 0.7924 - val_iou: 0.6167 - val_loss: 0.8674\n",
      "Epoch 76/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5578 - loss: 0.8056\n",
      "Epoch 76: saving model to ./checkpoints/cp-0076.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5578 - loss: 0.8056 - val_iou: 0.2263 - val_loss: 0.9108\n",
      "Epoch 77/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5799 - loss: 0.7831\n",
      "Epoch 77: saving model to ./checkpoints/cp-0077.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5799 - loss: 0.7831 - val_iou: 0.5984 - val_loss: 0.9320\n",
      "Epoch 78/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6256 - loss: 0.7718\n",
      "Epoch 78: saving model to ./checkpoints/cp-0078.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6256 - loss: 0.7718 - val_iou: 0.5763 - val_loss: 0.8838\n",
      "Epoch 79/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5563 - loss: 0.7995\n",
      "Epoch 79: saving model to ./checkpoints/cp-0079.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5563 - loss: 0.7995 - val_iou: 0.3217 - val_loss: 0.9052\n",
      "Epoch 80/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5121 - loss: 0.7995\n",
      "Epoch 80: saving model to ./checkpoints/cp-0080.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5121 - loss: 0.7995 - val_iou: 0.5919 - val_loss: 0.8308\n",
      "Epoch 81/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5601 - loss: 0.7902\n",
      "Epoch 81: saving model to ./checkpoints/cp-0081.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5601 - loss: 0.7902 - val_iou: 0.6407 - val_loss: 0.8346\n",
      "Epoch 82/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6121 - loss: 0.7794\n",
      "Epoch 82: saving model to ./checkpoints/cp-0082.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6120 - loss: 0.7794 - val_iou: 0.6350 - val_loss: 0.8194\n",
      "Epoch 83/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5017 - loss: 0.7866\n",
      "Epoch 83: saving model to ./checkpoints/cp-0083.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.5017 - loss: 0.7866 - val_iou: 0.6760 - val_loss: 0.8146\n",
      "Epoch 84/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6328 - loss: 0.7816\n",
      "Epoch 84: saving model to ./checkpoints/cp-0084.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.6328 - loss: 0.7816 - val_iou: 0.6426 - val_loss: 0.8430\n",
      "Epoch 85/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5314 - loss: 0.7753\n",
      "Epoch 85: saving model to ./checkpoints/cp-0085.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5314 - loss: 0.7753 - val_iou: 0.5022 - val_loss: 0.8237\n",
      "Epoch 86/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5630 - loss: 0.7829\n",
      "Epoch 86: saving model to ./checkpoints/cp-0086.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5630 - loss: 0.7829 - val_iou: 0.6380 - val_loss: 0.8562\n",
      "Epoch 87/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6363 - loss: 0.7879\n",
      "Epoch 87: saving model to ./checkpoints/cp-0087.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6363 - loss: 0.7879 - val_iou: 0.1616 - val_loss: 0.9568\n",
      "Epoch 88/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.4864 - loss: 0.7969\n",
      "Epoch 88: saving model to ./checkpoints/cp-0088.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.4864 - loss: 0.7969 - val_iou: 0.6590 - val_loss: 0.8702\n",
      "Epoch 89/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5808 - loss: 0.7854\n",
      "Epoch 89: saving model to ./checkpoints/cp-0089.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5808 - loss: 0.7854 - val_iou: 0.6672 - val_loss: 0.8307\n",
      "Epoch 90/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5965 - loss: 0.7842\n",
      "Epoch 90: saving model to ./checkpoints/cp-0090.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5965 - loss: 0.7842 - val_iou: 0.6505 - val_loss: 0.8557\n",
      "Epoch 91/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6084 - loss: 0.7806\n",
      "Epoch 91: saving model to ./checkpoints/cp-0091.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6084 - loss: 0.7806 - val_iou: 0.6274 - val_loss: 0.8575\n",
      "Epoch 92/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5192 - loss: 0.7929\n",
      "Epoch 92: saving model to ./checkpoints/cp-0092.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5193 - loss: 0.7929 - val_iou: 0.6449 - val_loss: 0.8494\n",
      "Epoch 93/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5739 - loss: 0.7870\n",
      "Epoch 93: saving model to ./checkpoints/cp-0093.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.5739 - loss: 0.7870 - val_iou: 0.6895 - val_loss: 0.8317\n",
      "Epoch 94/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5974 - loss: 0.7857\n",
      "Epoch 94: saving model to ./checkpoints/cp-0094.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5974 - loss: 0.7857 - val_iou: 0.6376 - val_loss: 0.8592\n",
      "Epoch 95/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5525 - loss: 0.7779\n",
      "Epoch 95: saving model to ./checkpoints/cp-0095.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5526 - loss: 0.7779 - val_iou: 0.6753 - val_loss: 0.8327\n",
      "Epoch 96/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6121 - loss: 0.7822\n",
      "Epoch 96: saving model to ./checkpoints/cp-0096.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6121 - loss: 0.7822 - val_iou: 0.7090 - val_loss: 0.8082\n",
      "Epoch 97/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6525 - loss: 0.7708\n",
      "Epoch 97: saving model to ./checkpoints/cp-0097.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6525 - loss: 0.7708 - val_iou: 0.4668 - val_loss: 0.9233\n",
      "Epoch 98/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5737 - loss: 0.7830\n",
      "Epoch 98: saving model to ./checkpoints/cp-0098.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5737 - loss: 0.7830 - val_iou: 0.6433 - val_loss: 0.8612\n",
      "Epoch 99/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6273 - loss: 0.7817\n",
      "Epoch 99: saving model to ./checkpoints/cp-0099.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.6273 - loss: 0.7817 - val_iou: 0.6072 - val_loss: 0.8556\n",
      "Epoch 100/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6743 - loss: 0.7590\n",
      "Epoch 100: saving model to ./checkpoints/cp-0100.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6743 - loss: 0.7591 - val_iou: 0.6006 - val_loss: 0.8532\n",
      "Epoch 101/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5330 - loss: 0.7693\n",
      "Epoch 101: saving model to ./checkpoints/cp-0101.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5330 - loss: 0.7693 - val_iou: 0.6359 - val_loss: 0.8528\n",
      "Epoch 102/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6308 - loss: 0.7702\n",
      "Epoch 102: saving model to ./checkpoints/cp-0102.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6308 - loss: 0.7702 - val_iou: 0.6761 - val_loss: 0.8203\n",
      "Epoch 103/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5974 - loss: 0.7918\n",
      "Epoch 103: saving model to ./checkpoints/cp-0103.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5973 - loss: 0.7918 - val_iou: 0.6746 - val_loss: 0.8213\n",
      "Epoch 104/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5598 - loss: 0.7726\n",
      "Epoch 104: saving model to ./checkpoints/cp-0104.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5598 - loss: 0.7726 - val_iou: 0.7013 - val_loss: 0.8459\n",
      "Epoch 105/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6217 - loss: 0.7834\n",
      "Epoch 105: saving model to ./checkpoints/cp-0105.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6217 - loss: 0.7834 - val_iou: 0.6214 - val_loss: 0.8202\n",
      "Epoch 106/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6412 - loss: 0.7878\n",
      "Epoch 106: saving model to ./checkpoints/cp-0106.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6412 - loss: 0.7878 - val_iou: 0.6757 - val_loss: 0.8039\n",
      "Epoch 107/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6327 - loss: 0.7743\n",
      "Epoch 107: saving model to ./checkpoints/cp-0107.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6327 - loss: 0.7743 - val_iou: 0.6735 - val_loss: 0.8203\n",
      "Epoch 108/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6343 - loss: 0.7878\n",
      "Epoch 108: saving model to ./checkpoints/cp-0108.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6343 - loss: 0.7878 - val_iou: 0.6880 - val_loss: 0.8106\n",
      "Epoch 109/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5917 - loss: 0.7736\n",
      "Epoch 109: saving model to ./checkpoints/cp-0109.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5917 - loss: 0.7736 - val_iou: 0.6547 - val_loss: 0.9230\n",
      "Epoch 110/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6900 - loss: 0.7688\n",
      "Epoch 110: saving model to ./checkpoints/cp-0110.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6900 - loss: 0.7688 - val_iou: 0.6621 - val_loss: 0.8533\n",
      "Epoch 111/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6657 - loss: 0.7841\n",
      "Epoch 111: saving model to ./checkpoints/cp-0111.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6657 - loss: 0.7841 - val_iou: 0.5901 - val_loss: 0.8514\n",
      "Epoch 112/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5906 - loss: 0.7690\n",
      "Epoch 112: saving model to ./checkpoints/cp-0112.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5907 - loss: 0.7690 - val_iou: 0.6612 - val_loss: 0.8480\n",
      "Epoch 113/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6328 - loss: 0.7825\n",
      "Epoch 113: saving model to ./checkpoints/cp-0113.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6328 - loss: 0.7825 - val_iou: 0.6260 - val_loss: 0.8191\n",
      "Epoch 114/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6670 - loss: 0.7676\n",
      "Epoch 114: saving model to ./checkpoints/cp-0114.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6670 - loss: 0.7676 - val_iou: 0.6663 - val_loss: 0.8114\n",
      "Epoch 115/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6281 - loss: 0.7833\n",
      "Epoch 115: saving model to ./checkpoints/cp-0115.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6281 - loss: 0.7833 - val_iou: 0.6720 - val_loss: 0.8234\n",
      "Epoch 116/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6467 - loss: 0.7741\n",
      "Epoch 116: saving model to ./checkpoints/cp-0116.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6467 - loss: 0.7741 - val_iou: 0.6629 - val_loss: 0.8140\n",
      "Epoch 117/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6810 - loss: 0.7536\n",
      "Epoch 117: saving model to ./checkpoints/cp-0117.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6810 - loss: 0.7536 - val_iou: 0.6803 - val_loss: 0.8133\n",
      "Epoch 118/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6738 - loss: 0.7845\n",
      "Epoch 118: saving model to ./checkpoints/cp-0118.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.6738 - loss: 0.7845 - val_iou: 0.6969 - val_loss: 0.8134\n",
      "Epoch 119/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6443 - loss: 0.7691\n",
      "Epoch 119: saving model to ./checkpoints/cp-0119.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6443 - loss: 0.7691 - val_iou: 0.6482 - val_loss: 0.8003\n",
      "Epoch 120/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6499 - loss: 0.7772\n",
      "Epoch 120: saving model to ./checkpoints/cp-0120.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6499 - loss: 0.7772 - val_iou: 0.6884 - val_loss: 0.8471\n",
      "Epoch 121/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6564 - loss: 0.7711\n",
      "Epoch 121: saving model to ./checkpoints/cp-0121.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6563 - loss: 0.7711 - val_iou: 0.6406 - val_loss: 0.8194\n",
      "Epoch 122/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6200 - loss: 0.7774\n",
      "Epoch 122: saving model to ./checkpoints/cp-0122.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6200 - loss: 0.7774 - val_iou: 0.6417 - val_loss: 0.7989\n",
      "Epoch 123/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6254 - loss: 0.7582\n",
      "Epoch 123: saving model to ./checkpoints/cp-0123.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6254 - loss: 0.7582 - val_iou: 0.6887 - val_loss: 0.7929\n",
      "Epoch 124/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6340 - loss: 0.7533\n",
      "Epoch 124: saving model to ./checkpoints/cp-0124.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6340 - loss: 0.7533 - val_iou: 0.6305 - val_loss: 0.8024\n",
      "Epoch 125/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5862 - loss: 0.7797\n",
      "Epoch 125: saving model to ./checkpoints/cp-0125.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5862 - loss: 0.7797 - val_iou: 0.6620 - val_loss: 0.8276\n",
      "Epoch 126/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6644 - loss: 0.7608\n",
      "Epoch 126: saving model to ./checkpoints/cp-0126.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6644 - loss: 0.7608 - val_iou: 0.7252 - val_loss: 0.7867\n",
      "Epoch 127/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5901 - loss: 0.7777\n",
      "Epoch 127: saving model to ./checkpoints/cp-0127.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5901 - loss: 0.7777 - val_iou: 0.6949 - val_loss: 0.8313\n",
      "Epoch 128/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6562 - loss: 0.7663\n",
      "Epoch 128: saving model to ./checkpoints/cp-0128.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6562 - loss: 0.7663 - val_iou: 0.6324 - val_loss: 0.8381\n",
      "Epoch 129/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6234 - loss: 0.7759\n",
      "Epoch 129: saving model to ./checkpoints/cp-0129.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6234 - loss: 0.7759 - val_iou: 0.7021 - val_loss: 0.8212\n",
      "Epoch 130/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6620 - loss: 0.7660\n",
      "Epoch 130: saving model to ./checkpoints/cp-0130.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6620 - loss: 0.7660 - val_iou: 0.6783 - val_loss: 0.8279\n",
      "Epoch 131/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6410 - loss: 0.7610\n",
      "Epoch 131: saving model to ./checkpoints/cp-0131.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6410 - loss: 0.7610 - val_iou: 0.6913 - val_loss: 0.7911\n",
      "Epoch 132/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6512 - loss: 0.7562\n",
      "Epoch 132: saving model to ./checkpoints/cp-0132.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6512 - loss: 0.7562 - val_iou: 0.6181 - val_loss: 0.8399\n",
      "Epoch 133/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7089 - loss: 0.7538\n",
      "Epoch 133: saving model to ./checkpoints/cp-0133.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7089 - loss: 0.7538 - val_iou: 0.7019 - val_loss: 0.8108\n",
      "Epoch 134/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7005 - loss: 0.7819\n",
      "Epoch 134: saving model to ./checkpoints/cp-0134.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7005 - loss: 0.7819 - val_iou: 0.6485 - val_loss: 0.8201\n",
      "Epoch 135/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6466 - loss: 0.7560\n",
      "Epoch 135: saving model to ./checkpoints/cp-0135.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6466 - loss: 0.7560 - val_iou: 0.6671 - val_loss: 0.8359\n",
      "Epoch 136/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6113 - loss: 0.7848\n",
      "Epoch 136: saving model to ./checkpoints/cp-0136.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6114 - loss: 0.7848 - val_iou: 0.6443 - val_loss: 0.8444\n",
      "Epoch 137/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5932 - loss: 0.7690\n",
      "Epoch 137: saving model to ./checkpoints/cp-0137.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5932 - loss: 0.7690 - val_iou: 0.6540 - val_loss: 0.8131\n",
      "Epoch 138/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6456 - loss: 0.7734\n",
      "Epoch 138: saving model to ./checkpoints/cp-0138.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6456 - loss: 0.7734 - val_iou: 0.6462 - val_loss: 0.8479\n",
      "Epoch 139/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5400 - loss: 0.7677\n",
      "Epoch 139: saving model to ./checkpoints/cp-0139.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5401 - loss: 0.7677 - val_iou: 0.6749 - val_loss: 0.8556\n",
      "Epoch 140/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6785 - loss: 0.7741\n",
      "Epoch 140: saving model to ./checkpoints/cp-0140.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6785 - loss: 0.7741 - val_iou: 0.6999 - val_loss: 0.7995\n",
      "Epoch 141/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7083 - loss: 0.7746\n",
      "Epoch 141: saving model to ./checkpoints/cp-0141.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7083 - loss: 0.7746 - val_iou: 0.6715 - val_loss: 0.8276\n",
      "Epoch 142/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7196 - loss: 0.7602\n",
      "Epoch 142: saving model to ./checkpoints/cp-0142.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7196 - loss: 0.7602 - val_iou: 0.7060 - val_loss: 0.8126\n",
      "Epoch 143/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6234 - loss: 0.7583\n",
      "Epoch 143: saving model to ./checkpoints/cp-0143.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6233 - loss: 0.7583 - val_iou: 0.7049 - val_loss: 0.8038\n",
      "Epoch 144/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5668 - loss: 0.7693\n",
      "Epoch 144: saving model to ./checkpoints/cp-0144.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.5669 - loss: 0.7693 - val_iou: 0.6589 - val_loss: 0.8134\n",
      "Epoch 145/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6415 - loss: 0.7604\n",
      "Epoch 145: saving model to ./checkpoints/cp-0145.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6415 - loss: 0.7604 - val_iou: 0.6416 - val_loss: 0.8012\n",
      "Epoch 146/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6380 - loss: 0.7725\n",
      "Epoch 146: saving model to ./checkpoints/cp-0146.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6380 - loss: 0.7725 - val_iou: 0.6441 - val_loss: 0.8246\n",
      "Epoch 147/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6147 - loss: 0.7757\n",
      "Epoch 147: saving model to ./checkpoints/cp-0147.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6147 - loss: 0.7757 - val_iou: 0.6608 - val_loss: 0.8066\n",
      "Epoch 148/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6864 - loss: 0.7541\n",
      "Epoch 148: saving model to ./checkpoints/cp-0148.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.6864 - loss: 0.7541 - val_iou: 0.7108 - val_loss: 0.8432\n",
      "Epoch 149/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6899 - loss: 0.7644\n",
      "Epoch 149: saving model to ./checkpoints/cp-0149.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6899 - loss: 0.7644 - val_iou: 0.6850 - val_loss: 0.8440\n",
      "Epoch 150/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7158 - loss: 0.7643\n",
      "Epoch 150: saving model to ./checkpoints/cp-0150.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7158 - loss: 0.7643 - val_iou: 0.6141 - val_loss: 0.8333\n",
      "Epoch 151/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6033 - loss: 0.7527\n",
      "Epoch 151: saving model to ./checkpoints/cp-0151.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6033 - loss: 0.7528 - val_iou: 0.6915 - val_loss: 0.7982\n",
      "Epoch 152/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7067 - loss: 0.7793\n",
      "Epoch 152: saving model to ./checkpoints/cp-0152.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7067 - loss: 0.7793 - val_iou: 0.7106 - val_loss: 0.7995\n",
      "Epoch 153/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7044 - loss: 0.7641\n",
      "Epoch 153: saving model to ./checkpoints/cp-0153.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7044 - loss: 0.7641 - val_iou: 0.6776 - val_loss: 0.7964\n",
      "Epoch 154/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7075 - loss: 0.7724\n",
      "Epoch 154: saving model to ./checkpoints/cp-0154.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7075 - loss: 0.7724 - val_iou: 0.7094 - val_loss: 0.8164\n",
      "Epoch 155/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6669 - loss: 0.7590\n",
      "Epoch 155: saving model to ./checkpoints/cp-0155.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6669 - loss: 0.7590 - val_iou: 0.6917 - val_loss: 0.7889\n",
      "Epoch 156/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7089 - loss: 0.7667\n",
      "Epoch 156: saving model to ./checkpoints/cp-0156.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7089 - loss: 0.7667 - val_iou: 0.7001 - val_loss: 0.8152\n",
      "Epoch 157/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7232 - loss: 0.7596\n",
      "Epoch 157: saving model to ./checkpoints/cp-0157.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7232 - loss: 0.7596 - val_iou: 0.6391 - val_loss: 0.7929\n",
      "Epoch 158/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7143 - loss: 0.7741\n",
      "Epoch 158: saving model to ./checkpoints/cp-0158.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7143 - loss: 0.7741 - val_iou: 0.7020 - val_loss: 0.7989\n",
      "Epoch 159/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7219 - loss: 0.7834\n",
      "Epoch 159: saving model to ./checkpoints/cp-0159.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7219 - loss: 0.7834 - val_iou: 0.6996 - val_loss: 0.7864\n",
      "Epoch 160/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7261 - loss: 0.7537\n",
      "Epoch 160: saving model to ./checkpoints/cp-0160.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7261 - loss: 0.7537 - val_iou: 0.6890 - val_loss: 0.8746\n",
      "Epoch 161/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7212 - loss: 0.7662\n",
      "Epoch 161: saving model to ./checkpoints/cp-0161.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7212 - loss: 0.7662 - val_iou: 0.5997 - val_loss: 0.9275\n",
      "Epoch 162/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6736 - loss: 0.7760\n",
      "Epoch 162: saving model to ./checkpoints/cp-0162.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6737 - loss: 0.7760 - val_iou: 0.7301 - val_loss: 0.8255\n",
      "Epoch 163/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7453 - loss: 0.7524\n",
      "Epoch 163: saving model to ./checkpoints/cp-0163.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7453 - loss: 0.7524 - val_iou: 0.6640 - val_loss: 0.8347\n",
      "Epoch 164/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7565 - loss: 0.7607\n",
      "Epoch 164: saving model to ./checkpoints/cp-0164.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7565 - loss: 0.7607 - val_iou: 0.7204 - val_loss: 0.8239\n",
      "Epoch 165/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6897 - loss: 0.7677\n",
      "Epoch 165: saving model to ./checkpoints/cp-0165.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6897 - loss: 0.7677 - val_iou: 0.7271 - val_loss: 0.7911\n",
      "Epoch 166/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7136 - loss: 0.7592\n",
      "Epoch 166: saving model to ./checkpoints/cp-0166.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7136 - loss: 0.7592 - val_iou: 0.6344 - val_loss: 0.7871\n",
      "Epoch 167/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6691 - loss: 0.7720\n",
      "Epoch 167: saving model to ./checkpoints/cp-0167.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6691 - loss: 0.7720 - val_iou: 0.6726 - val_loss: 0.8070\n",
      "Epoch 168/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7323 - loss: 0.7771\n",
      "Epoch 168: saving model to ./checkpoints/cp-0168.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7322 - loss: 0.7771 - val_iou: 0.6746 - val_loss: 0.8000\n",
      "Epoch 169/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6474 - loss: 0.7464\n",
      "Epoch 169: saving model to ./checkpoints/cp-0169.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6474 - loss: 0.7464 - val_iou: 0.7357 - val_loss: 0.7887\n",
      "Epoch 170/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7419 - loss: 0.7449\n",
      "Epoch 170: saving model to ./checkpoints/cp-0170.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7419 - loss: 0.7449 - val_iou: 0.6807 - val_loss: 0.8269\n",
      "Epoch 171/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7476 - loss: 0.7661\n",
      "Epoch 171: saving model to ./checkpoints/cp-0171.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7476 - loss: 0.7661 - val_iou: 0.6428 - val_loss: 0.8438\n",
      "Epoch 172/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6958 - loss: 0.7562\n",
      "Epoch 172: saving model to ./checkpoints/cp-0172.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6958 - loss: 0.7562 - val_iou: 0.6902 - val_loss: 0.8213\n",
      "Epoch 173/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7636 - loss: 0.7570\n",
      "Epoch 173: saving model to ./checkpoints/cp-0173.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7635 - loss: 0.7570 - val_iou: 0.6293 - val_loss: 0.8110\n",
      "Epoch 174/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6549 - loss: 0.7647\n",
      "Epoch 174: saving model to ./checkpoints/cp-0174.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6549 - loss: 0.7647 - val_iou: 0.6457 - val_loss: 0.8249\n",
      "Epoch 175/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6861 - loss: 0.7506\n",
      "Epoch 175: saving model to ./checkpoints/cp-0175.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6861 - loss: 0.7506 - val_iou: 0.7026 - val_loss: 0.8183\n",
      "Epoch 176/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7431 - loss: 0.7628\n",
      "Epoch 176: saving model to ./checkpoints/cp-0176.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7431 - loss: 0.7628 - val_iou: 0.6904 - val_loss: 0.8354\n",
      "Epoch 177/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7687 - loss: 0.7605\n",
      "Epoch 177: saving model to ./checkpoints/cp-0177.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7687 - loss: 0.7605 - val_iou: 0.6532 - val_loss: 0.8418\n",
      "Epoch 178/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7395 - loss: 0.7497\n",
      "Epoch 178: saving model to ./checkpoints/cp-0178.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7395 - loss: 0.7497 - val_iou: 0.6985 - val_loss: 0.8105\n",
      "Epoch 179/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7065 - loss: 0.7730\n",
      "Epoch 179: saving model to ./checkpoints/cp-0179.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7065 - loss: 0.7730 - val_iou: 0.7068 - val_loss: 0.8196\n",
      "Epoch 180/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6866 - loss: 0.7571\n",
      "Epoch 180: saving model to ./checkpoints/cp-0180.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.6866 - loss: 0.7571 - val_iou: 0.7103 - val_loss: 0.8654\n",
      "Epoch 181/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7355 - loss: 0.7736\n",
      "Epoch 181: saving model to ./checkpoints/cp-0181.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7355 - loss: 0.7735 - val_iou: 0.7158 - val_loss: 0.8282\n",
      "Epoch 182/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7252 - loss: 0.7486\n",
      "Epoch 182: saving model to ./checkpoints/cp-0182.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7252 - loss: 0.7486 - val_iou: 0.6882 - val_loss: 0.8378\n",
      "Epoch 183/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5662 - loss: 0.7699\n",
      "Epoch 183: saving model to ./checkpoints/cp-0183.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.5662 - loss: 0.7699 - val_iou: 0.7116 - val_loss: 0.8352\n",
      "Epoch 184/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7289 - loss: 0.7515\n",
      "Epoch 184: saving model to ./checkpoints/cp-0184.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7289 - loss: 0.7515 - val_iou: 0.7022 - val_loss: 0.7906\n",
      "Epoch 185/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6495 - loss: 0.7477\n",
      "Epoch 185: saving model to ./checkpoints/cp-0185.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6495 - loss: 0.7477 - val_iou: 0.6945 - val_loss: 0.8302\n",
      "Epoch 186/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6972 - loss: 0.7655\n",
      "Epoch 186: saving model to ./checkpoints/cp-0186.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6972 - loss: 0.7655 - val_iou: 0.6937 - val_loss: 0.8310\n",
      "Epoch 187/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7241 - loss: 0.7621\n",
      "Epoch 187: saving model to ./checkpoints/cp-0187.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7241 - loss: 0.7621 - val_iou: 0.6725 - val_loss: 0.8181\n",
      "Epoch 188/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6989 - loss: 0.7548\n",
      "Epoch 188: saving model to ./checkpoints/cp-0188.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6989 - loss: 0.7548 - val_iou: 0.7174 - val_loss: 0.8141\n",
      "Epoch 189/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7587 - loss: 0.7583\n",
      "Epoch 189: saving model to ./checkpoints/cp-0189.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7587 - loss: 0.7583 - val_iou: 0.7502 - val_loss: 0.7886\n",
      "Epoch 190/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.6917 - loss: 0.7665\n",
      "Epoch 190: saving model to ./checkpoints/cp-0190.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.6917 - loss: 0.7665 - val_iou: 0.7272 - val_loss: 0.7953\n",
      "Epoch 191/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7570 - loss: 0.7644\n",
      "Epoch 191: saving model to ./checkpoints/cp-0191.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.7570 - loss: 0.7644 - val_iou: 0.7032 - val_loss: 0.7891\n",
      "Epoch 192/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7611 - loss: 0.7532\n",
      "Epoch 192: saving model to ./checkpoints/cp-0192.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7611 - loss: 0.7532 - val_iou: 0.6984 - val_loss: 0.8185\n",
      "Epoch 193/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7273 - loss: 0.7508\n",
      "Epoch 193: saving model to ./checkpoints/cp-0193.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7273 - loss: 0.7508 - val_iou: 0.6637 - val_loss: 0.8131\n",
      "Epoch 194/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7029 - loss: 0.7635\n",
      "Epoch 194: saving model to ./checkpoints/cp-0194.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7029 - loss: 0.7635 - val_iou: 0.6489 - val_loss: 0.7865\n",
      "Epoch 195/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7022 - loss: 0.7436\n",
      "Epoch 195: saving model to ./checkpoints/cp-0195.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7023 - loss: 0.7437 - val_iou: 0.7676 - val_loss: 0.7928\n",
      "Epoch 196/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7367 - loss: 0.7554\n",
      "Epoch 196: saving model to ./checkpoints/cp-0196.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7367 - loss: 0.7554 - val_iou: 0.7399 - val_loss: 0.8010\n",
      "Epoch 197/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7431 - loss: 0.7644\n",
      "Epoch 197: saving model to ./checkpoints/cp-0197.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7432 - loss: 0.7644 - val_iou: 0.7122 - val_loss: 0.8718\n",
      "Epoch 198/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7276 - loss: 0.7508\n",
      "Epoch 198: saving model to ./checkpoints/cp-0198.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7276 - loss: 0.7508 - val_iou: 0.6164 - val_loss: 0.8850\n",
      "Epoch 199/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.7342 - loss: 0.7635\n",
      "Epoch 199: saving model to ./checkpoints/cp-0199.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 153ms/step - iou: 0.7342 - loss: 0.7635 - val_iou: 0.0899 - val_loss: 0.9038\n",
      "Epoch 200/200\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - iou: 0.5395 - loss: 0.7709\n",
      "Epoch 200: saving model to ./checkpoints/cp-0200.weights.h5\n",
      "\u001b[1m1915/1915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 153ms/step - iou: 0.5395 - loss: 0.7709 - val_iou: 0.6272 - val_loss: 0.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7bca59b43f20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint Saving\n",
    "checkpoint_path = \"./checkpoints/cp-{epoch:04d}.weights.h5\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1,\n",
    "                                                 save_weights_only=True, save_freq='epoch') #save_freq=1850)\n",
    "\n",
    "\n",
    "print(\"---------------- fitting model ---------------------\")\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=2, epochs=200, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebae90-e916-4481-a657-ceaf9c8281e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
